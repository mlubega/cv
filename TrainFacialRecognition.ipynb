{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainFacialRecognition.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "V7NDfnsUNSkZ",
        "pVExTueVPP3F"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlubega/cv/blob/master/TrainFacialRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S85AJNF_PgBO",
        "colab_type": "code",
        "outputId": "464b38df-58b1-40c7-f4f8-76fa828fd48f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPJGJxbab3lP",
        "colab_type": "code",
        "outputId": "00b02218-35ae-42b7-d71d-daf7af1eefe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#Enable CUDA GPU\n",
        "!nvcc --version"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X6q1-9NUgPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Only need to do once\n",
        "#%cd /content/drive/My\\ Drive/City\\ Msc\\ Data\\ Science/ComputerVision/\n",
        "#!ls -l\n",
        "#!tar -xzvf crops.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg4esxfc6ADt",
        "colab_type": "code",
        "outputId": "3add18d3-ee6d-48c6-931c-218b34ae368a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "%cd /content/drive/My\\ Drive/City\\ Msc\\ Data\\ Science/ComputerVision/crops/\n",
        "!ls -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/City Msc Data Science/ComputerVision/crops\n",
            "total 19\n",
            "-rw------- 1 root root 6477 Apr 18 17:23  juan.jpg\n",
            "drwx------ 2 root root 4096 Apr 22 16:35 'model(?)'\n",
            "drwx------ 2 root root 4096 Apr 16 18:53  test\n",
            "drwx------ 2 root root 4096 Apr 16 18:53  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alZke1ghwxlC",
        "colab_type": "text"
      },
      "source": [
        "Downgrade OPENCV version to access SIFT/SURF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-oGXKp7Hhg9",
        "colab_type": "code",
        "outputId": "be68f2a7-7c23-49c0-c1c6-541c17ca93b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "!pip install opencv-python==3.4.2.16\n",
        "!pip install opencv-contrib-python==3.4.2.16"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opencv-python==3.4.2.16\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/7d/5042b668a8ed41d2a80b8c172f5efcd572e3c046c75ae029407e19b7fc68/opencv_python-3.4.2.16-cp36-cp36m-manylinux1_x86_64.whl (25.0MB)\n",
            "\u001b[K     |████████████████████████████████| 25.0MB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python==3.4.2.16) (1.16.3)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: opencv-python\n",
            "  Found existing installation: opencv-python 3.4.5.20\n",
            "    Uninstalling opencv-python-3.4.5.20:\n",
            "      Successfully uninstalled opencv-python-3.4.5.20\n",
            "Successfully installed opencv-python-3.4.2.16\n",
            "Collecting opencv-contrib-python==3.4.2.16\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/f1/66330f4042c4fb3b2d77a159db8e8916d9cdecc29bc8c1f56bc7f8a9bec9/opencv_contrib_python-3.4.2.16-cp36-cp36m-manylinux1_x86_64.whl (30.6MB)\n",
            "\u001b[K     |████████████████████████████████| 30.6MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-contrib-python==3.4.2.16) (1.16.3)\n",
            "Installing collected packages: opencv-contrib-python\n",
            "  Found existing installation: opencv-contrib-python 3.4.3.18\n",
            "    Uninstalling opencv-contrib-python-3.4.3.18:\n",
            "      Successfully uninstalled opencv-contrib-python-3.4.3.18\n",
            "Successfully installed opencv-contrib-python-3.4.2.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OiNOoQwaN7B",
        "colab_type": "text"
      },
      "source": [
        "# SVM/MLP Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DQ78uZfNKw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from functools import reduce\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.externals import joblib\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR09LfoMGccp",
        "colab_type": "code",
        "outputId": "8bea29c8-4ae7-456d-fad5-d67f26ddfd37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cv2.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.4.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9eK-E10OtmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import timeit\n",
        "import time\n",
        "\n",
        "class Timer(object):\n",
        "    def __init__(self, verbose=False):\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.start = timeit.default_timer()\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, *args):\n",
        "        self.end = timeit.default_timer()\n",
        "        self.secs = self.end - self.start\n",
        "        self.msecs = self.secs * 1000  # millisecs\n",
        "        if self.verbose:\n",
        "            print(\"elapsed time:\", self.msecs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alMT1O-WIWtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_DATA = 'train/'\n",
        "TEST_DATA  = 'test/'\n",
        "\n",
        "NUM_CLASSES = len(os.listdir(TRAIN_DATA))\n",
        "K = NUM_CLASSES * 5  # KMeans Classes\n",
        "\n",
        "sift = cv2.xfeatures2d.SIFT_create()\n",
        "surf = cv2.xfeatures2d.SURF_create()\n",
        "orb = cv2.ORB_create()\n",
        "\n",
        "def getSIFTfeatures(gray_img):\n",
        "    #sift = cv2.xfeatures2d.SIFT_create() #What threshold?\n",
        "    kp, desc = sift.detectAndCompute(gray_img, None)\n",
        "    return kp, desc\n",
        "\n",
        "def getSURFfeatures(gray_img):  \n",
        "    #surf = cv2.xfeatures2d.SURF_create() #what threshold?\n",
        "    surf.setExtended(True) # --> to expand to 128 dim.\n",
        "    kp, desc = surf.detectAndCompute(gray_img, None)\n",
        "    return kp, desc\n",
        "\n",
        "def getORBfeatures(gray_img):\n",
        "    # Initiate ORB detector\n",
        "    #orb = cv2.ORB_create()\n",
        "    # find the keypoints with ORB\n",
        "    kp = orb.detect(gray_img,None)\n",
        "    # compute the descriptors with ORB\n",
        "    kp, desc = orb.compute(gray_img, kp)\n",
        "    return kp, desc\n",
        "\n",
        "def extractFeatures(crop_list, featureFunc):\n",
        "    descriptors = {}\n",
        "    \n",
        "    for i in range(0, len(crop_list)):\n",
        "       # gray = cv2.cvtColor(crop_list[i], cv2.COLOR_BGR2GRAY)\n",
        "        kp, desc = featureFunc(crop_list[i])\n",
        "        if type(desc) == type(None):\n",
        "          print('No Features Extracted')\n",
        "          continue\n",
        "          \n",
        "        descriptors[i] = desc\n",
        "        \n",
        "    return descriptors\n",
        "  \n",
        "def groupAllFeatures(desc_hash):\n",
        "    all_desc = []\n",
        "    for person, crops in desc_hash.items():\n",
        "        for idx, descs in crops.items():\n",
        "            all_desc.extend(descs)\n",
        "            \n",
        "    return all_desc\n",
        "        \n",
        "\n",
        "def trainKMeans(descriptors):\n",
        "     \n",
        "    # Train KMeans\n",
        "    initial_size = 3 * K\n",
        "    batch_size = int(len(descriptors) / 3)  # What's a good metric to determine this number? \n",
        "    kmeans = MiniBatchKMeans(n_clusters=K, batch_size=batch_size, init_size=initial_size, verbose=0).fit(descriptors)\n",
        "    \n",
        "    return kmeans\n",
        "    \n",
        "def generateHistograms(descriptors, kmeans_centers):\n",
        "    \n",
        "    ## Generate Histogram \n",
        "    histograms = []\n",
        "    for i, desc in descriptors.items(): \n",
        "        preds = kmeans_centers.predict(desc)\n",
        "        hist, bin_edges=np.histogram(preds, bins=range(0, K)) # Normalize by number of keypoints?? \n",
        "        histograms.append(hist)\n",
        "    \n",
        "    return histograms\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Kui_j5JX8bE",
        "colab_type": "text"
      },
      "source": [
        "#### Extract features separately  in order to time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEyp-1oxNKl6",
        "colab_type": "code",
        "outputId": "50fc047c-9d61-4bb4-94f2-8c6faf10acb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2397
        }
      },
      "source": [
        "allSIFT = {}\n",
        "\n",
        "people = os.listdir(TRAIN_DATA)    \n",
        "\n",
        "wall_start, cpu_start = time.time(), time.clock()\n",
        "i, total = 0,len(people)\n",
        "\n",
        "with Timer() as t:\n",
        "  for person in people:\n",
        "      i += 1\n",
        "      print(\"Processing Sub Dir\", person, \"[\", i , \"/\", total, \"]\" )\n",
        "\n",
        "      #read in cropped data\n",
        "      crop_names = os.listdir(os.path.join(TRAIN_DATA, person))\n",
        "      crop_names = list(map(lambda x: os.path.join(TRAIN_DATA, person, x), crop_names)) \n",
        "      crops = [cv2.imread(x , cv2.IMREAD_GRAYSCALE) for x in crop_names ]\n",
        "\n",
        "      # get SIFT Features\n",
        "      sift_desc = extractFeatures(crops, getSIFTfeatures)\n",
        "      allSIFT[person] = sift_desc\n",
        "      print(\"Extracted SIFT\")\n",
        "\n",
        "print(\"\\n\",\"Time\", t.secs)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing Sub Dir 43 [ 1 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 66 [ 2 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 24 [ 3 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 8 [ 4 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 54 [ 5 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 22 [ 6 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 11 [ 7 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 76 [ 8 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 69 [ 9 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 74 [ 10 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 9 [ 11 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 13 [ 12 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 38 [ 13 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 81 [ 14 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 67 [ 15 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 55 [ 16 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 65 [ 17 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 41 [ 18 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 7 [ 19 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 45 [ 20 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 78 [ 21 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 50 [ 22 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 62 [ 23 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 44 [ 24 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 75 [ 25 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 60 [ 26 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 57 [ 27 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 40 [ 28 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 21 [ 29 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 15 [ 30 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 12 [ 31 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 61 [ 32 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 49 [ 33 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 77 [ 34 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 42 [ 35 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 48 [ 36 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 58 [ 37 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 3 [ 38 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 71 [ 39 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 46 [ 40 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 59 [ 41 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 52 [ 42 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 16 [ 43 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 36 [ 44 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 47 [ 45 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 79 [ 46 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 56 [ 47 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 2 [ 48 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 64 [ 49 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 39 [ 50 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 10 [ 51 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 68 [ 52 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 4 [ 53 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 5 [ 54 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 51 [ 55 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 80 [ 56 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 70 [ 57 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 33 [ 58 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 14 [ 59 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 17 [ 60 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 73 [ 61 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 37 [ 62 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 20 [ 63 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 72 [ 64 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 6 [ 65 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 53 [ 66 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 63 [ 67 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 34 [ 68 / 69 ]\n",
            "Extracted SIFT\n",
            "Processing Sub Dir 1 [ 69 / 69 ]\n",
            "Extracted SIFT\n",
            "\n",
            " Time 60.181477559000086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v05CFgmdNK6-",
        "colab_type": "code",
        "outputId": "537fe2cb-abb2-4d44-c484-7dc53013e719",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2397
        }
      },
      "source": [
        "allSURF = {}\n",
        "people = os.listdir(TRAIN_DATA)    \n",
        "\n",
        "i, total = 0,len(people)\n",
        "\n",
        "with Timer() as t:\n",
        "  for person in people:\n",
        "      i += 1\n",
        "      print(\"Processing Sub Dir\", person, \"[\", i , \"/\", total, \"]\" )\n",
        "\n",
        "\n",
        "      #read in cropped data\n",
        "      crop_names = os.listdir(os.path.join(TRAIN_DATA, person))\n",
        "      crop_names = list(map(lambda x: os.path.join(TRAIN_DATA, person, x), crop_names)) \n",
        "      crops = [cv2.imread(x , cv2.IMREAD_GRAYSCALE) for x in crop_names ]\n",
        "\n",
        "      # get SURF Features\n",
        "      surf_desc = extractFeatures(crops, getSURFfeatures)\n",
        "      allSURF[person] = surf_desc\n",
        "      print(\"Extracted SURF\")\n",
        "\n",
        "                 \n",
        "print(\"\\n\",\"Time\", t.secs)                 \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing Sub Dir 43 [ 1 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 66 [ 2 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 24 [ 3 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 8 [ 4 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 54 [ 5 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 22 [ 6 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 11 [ 7 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 76 [ 8 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 69 [ 9 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 74 [ 10 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 9 [ 11 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 13 [ 12 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 38 [ 13 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 81 [ 14 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 67 [ 15 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 55 [ 16 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 65 [ 17 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 41 [ 18 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 7 [ 19 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 45 [ 20 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 78 [ 21 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 50 [ 22 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 62 [ 23 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 44 [ 24 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 75 [ 25 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 60 [ 26 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 57 [ 27 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 40 [ 28 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 21 [ 29 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 15 [ 30 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 12 [ 31 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 61 [ 32 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 49 [ 33 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 77 [ 34 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 42 [ 35 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 48 [ 36 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 58 [ 37 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 3 [ 38 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 71 [ 39 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 46 [ 40 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 59 [ 41 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 52 [ 42 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 16 [ 43 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 36 [ 44 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 47 [ 45 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 79 [ 46 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 56 [ 47 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 2 [ 48 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 64 [ 49 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 39 [ 50 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 10 [ 51 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 68 [ 52 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 4 [ 53 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 5 [ 54 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 51 [ 55 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 80 [ 56 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 70 [ 57 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 33 [ 58 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 14 [ 59 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 17 [ 60 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 73 [ 61 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 37 [ 62 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 20 [ 63 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 72 [ 64 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 6 [ 65 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 53 [ 66 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 63 [ 67 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 34 [ 68 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 1 [ 69 / 69 ]\n",
            "Extracted SURF\n",
            "\n",
            " Time 93.72377456699996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-b8HdcENLIU",
        "colab_type": "code",
        "outputId": "cd94314b-0390-44df-b6bc-b993ebd660ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2669
        }
      },
      "source": [
        "allORB = {}\n",
        "\n",
        "people = os.listdir(TRAIN_DATA)    \n",
        "\n",
        "\n",
        "i, total = 0,len(people)\n",
        "with Timer() as t:\n",
        "  for person in people:\n",
        "      i += 1\n",
        "      print(\"Processing Sub Dir\", person, \"[\", i , \"/\", total, \"]\" )\n",
        "\n",
        "\n",
        "      #read in cropped data\n",
        "      crop_names = os.listdir(os.path.join(TRAIN_DATA, person))\n",
        "      crop_names = list(map(lambda x: os.path.join(TRAIN_DATA, person, x), crop_names)) \n",
        "      crops = [cv2.imread(x , cv2.IMREAD_GRAYSCALE) for x in crop_names ]\n",
        "\n",
        "      # get ORB Features\n",
        "      orb_desc = extractFeatures(crops, getORBfeatures)\n",
        "      allORB[person] = orb_desc\n",
        "      print(\"Extracted ORB\")\n",
        "                 \n",
        "print(\"\\n\", \"Time\", t.secs)                  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing Sub Dir 43 [ 1 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 66 [ 2 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 24 [ 3 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 8 [ 4 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 54 [ 5 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 22 [ 6 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 11 [ 7 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 76 [ 8 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 69 [ 9 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 74 [ 10 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 9 [ 11 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 13 [ 12 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 38 [ 13 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 81 [ 14 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 67 [ 15 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 55 [ 16 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 65 [ 17 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 41 [ 18 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 7 [ 19 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 45 [ 20 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 78 [ 21 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 50 [ 22 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 62 [ 23 / 69 ]\n",
            "No Features Extracted\n",
            "No Features Extracted\n",
            "No Features Extracted\n",
            "Extracted ORB\n",
            "Processing Sub Dir 44 [ 24 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 75 [ 25 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 60 [ 26 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 57 [ 27 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 40 [ 28 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 21 [ 29 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 15 [ 30 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 12 [ 31 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 61 [ 32 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 49 [ 33 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 77 [ 34 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 42 [ 35 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 48 [ 36 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 58 [ 37 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 3 [ 38 / 69 ]\n",
            "No Features Extracted\n",
            "No Features Extracted\n",
            "No Features Extracted\n",
            "No Features Extracted\n",
            "No Features Extracted\n",
            "No Features Extracted\n",
            "Extracted ORB\n",
            "Processing Sub Dir 71 [ 39 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 46 [ 40 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 59 [ 41 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 52 [ 42 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 16 [ 43 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 36 [ 44 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 47 [ 45 / 69 ]\n",
            "No Features Extracted\n",
            "Extracted ORB\n",
            "Processing Sub Dir 79 [ 46 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 56 [ 47 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 2 [ 48 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 64 [ 49 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 39 [ 50 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 10 [ 51 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 68 [ 52 / 69 ]\n",
            "No Features Extracted\n",
            "No Features Extracted\n",
            "No Features Extracted\n",
            "No Features Extracted\n",
            "No Features Extracted\n",
            "Extracted ORB\n",
            "Processing Sub Dir 4 [ 53 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 5 [ 54 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 51 [ 55 / 69 ]\n",
            "No Features Extracted\n",
            "Extracted ORB\n",
            "Processing Sub Dir 80 [ 56 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 70 [ 57 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 33 [ 58 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 14 [ 59 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 17 [ 60 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 73 [ 61 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 37 [ 62 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 20 [ 63 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 72 [ 64 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 6 [ 65 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 53 [ 66 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 63 [ 67 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 34 [ 68 / 69 ]\n",
            "Extracted ORB\n",
            "Processing Sub Dir 1 [ 69 / 69 ]\n",
            "Extracted ORB\n",
            "\n",
            " Time 17.94920523399969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WaRpRmxSu3s",
        "colab_type": "text"
      },
      "source": [
        "#### Create Bag of Visual Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aomdV9f9Eube",
        "colab_type": "code",
        "outputId": "28d8639e-1b2e-4e03-c5b1-e3d6aef168e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "### Group Features\n",
        "\n",
        "sift_matrix = groupAllFeatures(allSIFT)\n",
        "surf_matrix = groupAllFeatures(allSURF)\n",
        "orb_matrix = groupAllFeatures(allORB)\n",
        "\n",
        "### Train KMeans\n",
        "sift_kmeans = None\n",
        "surf_kmeans = None\n",
        "orb_kmeans = None\n",
        "\n",
        "print(\"Training SIFT KMeans\")\n",
        "sift_kmeans = trainKMeans(sift_matrix)\n",
        "\n",
        "print(\"Training SURF KMeans\")\n",
        "surf_kmeans = trainKMeans(surf_matrix)\n",
        "\n",
        "print(\"Training ORB KMeans\")\n",
        "orb_kmeans = trainKMeans(orb_matrix)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training SIFT KMeans\n",
            "Training SURF KMeans\n",
            "Training ORB KMeans\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4Sqo4esRzQQ",
        "colab_type": "text"
      },
      "source": [
        "#### Prepare Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A9xkhVRR2pr",
        "colab_type": "code",
        "outputId": "20966b20-2b55-4aca-e1f5-1d3a2bb478fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1326
        }
      },
      "source": [
        "sift_train_feature_vec = [[], []]   \n",
        "   \n",
        "\n",
        "print(\"SURF Training Data\")\n",
        "people = os.listdir(TRAIN_DATA)    \n",
        "\n",
        "i, total = 0,len(people)\n",
        "with Timer() as t: \n",
        "  for person in people:\n",
        "      i += 1\n",
        "      print(\"Processing Sub Dir\", person, \"[\", i , \"/\", total, \"]\" )\n",
        "\n",
        "\n",
        "      sift_histograms = generateHistograms(allSIFT[person], sift_kmeans)\n",
        "      sift_train_feature_vec[0].extend(sift_histograms)\n",
        "      sift_train_feature_vec[1].extend([person] * len(sift_histograms))\n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "print(\"\\n\", \"Time\", t.secs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SURF Training Data\n",
            "Processing Sub Dir 43 [ 1 / 69 ]\n",
            "Processing Sub Dir 66 [ 2 / 69 ]\n",
            "Processing Sub Dir 24 [ 3 / 69 ]\n",
            "Processing Sub Dir 8 [ 4 / 69 ]\n",
            "Processing Sub Dir 54 [ 5 / 69 ]\n",
            "Processing Sub Dir 22 [ 6 / 69 ]\n",
            "Processing Sub Dir 11 [ 7 / 69 ]\n",
            "Processing Sub Dir 76 [ 8 / 69 ]\n",
            "Processing Sub Dir 69 [ 9 / 69 ]\n",
            "Processing Sub Dir 74 [ 10 / 69 ]\n",
            "Processing Sub Dir 9 [ 11 / 69 ]\n",
            "Processing Sub Dir 13 [ 12 / 69 ]\n",
            "Processing Sub Dir 38 [ 13 / 69 ]\n",
            "Processing Sub Dir 81 [ 14 / 69 ]\n",
            "Processing Sub Dir 67 [ 15 / 69 ]\n",
            "Processing Sub Dir 55 [ 16 / 69 ]\n",
            "Processing Sub Dir 65 [ 17 / 69 ]\n",
            "Processing Sub Dir 41 [ 18 / 69 ]\n",
            "Processing Sub Dir 7 [ 19 / 69 ]\n",
            "Processing Sub Dir 45 [ 20 / 69 ]\n",
            "Processing Sub Dir 78 [ 21 / 69 ]\n",
            "Processing Sub Dir 50 [ 22 / 69 ]\n",
            "Processing Sub Dir 62 [ 23 / 69 ]\n",
            "Processing Sub Dir 44 [ 24 / 69 ]\n",
            "Processing Sub Dir 75 [ 25 / 69 ]\n",
            "Processing Sub Dir 60 [ 26 / 69 ]\n",
            "Processing Sub Dir 57 [ 27 / 69 ]\n",
            "Processing Sub Dir 40 [ 28 / 69 ]\n",
            "Processing Sub Dir 21 [ 29 / 69 ]\n",
            "Processing Sub Dir 15 [ 30 / 69 ]\n",
            "Processing Sub Dir 12 [ 31 / 69 ]\n",
            "Processing Sub Dir 61 [ 32 / 69 ]\n",
            "Processing Sub Dir 49 [ 33 / 69 ]\n",
            "Processing Sub Dir 77 [ 34 / 69 ]\n",
            "Processing Sub Dir 42 [ 35 / 69 ]\n",
            "Processing Sub Dir 48 [ 36 / 69 ]\n",
            "Processing Sub Dir 58 [ 37 / 69 ]\n",
            "Processing Sub Dir 3 [ 38 / 69 ]\n",
            "Processing Sub Dir 71 [ 39 / 69 ]\n",
            "Processing Sub Dir 46 [ 40 / 69 ]\n",
            "Processing Sub Dir 59 [ 41 / 69 ]\n",
            "Processing Sub Dir 52 [ 42 / 69 ]\n",
            "Processing Sub Dir 16 [ 43 / 69 ]\n",
            "Processing Sub Dir 36 [ 44 / 69 ]\n",
            "Processing Sub Dir 47 [ 45 / 69 ]\n",
            "Processing Sub Dir 79 [ 46 / 69 ]\n",
            "Processing Sub Dir 56 [ 47 / 69 ]\n",
            "Processing Sub Dir 2 [ 48 / 69 ]\n",
            "Processing Sub Dir 64 [ 49 / 69 ]\n",
            "Processing Sub Dir 39 [ 50 / 69 ]\n",
            "Processing Sub Dir 10 [ 51 / 69 ]\n",
            "Processing Sub Dir 68 [ 52 / 69 ]\n",
            "Processing Sub Dir 4 [ 53 / 69 ]\n",
            "Processing Sub Dir 5 [ 54 / 69 ]\n",
            "Processing Sub Dir 51 [ 55 / 69 ]\n",
            "Processing Sub Dir 80 [ 56 / 69 ]\n",
            "Processing Sub Dir 70 [ 57 / 69 ]\n",
            "Processing Sub Dir 33 [ 58 / 69 ]\n",
            "Processing Sub Dir 14 [ 59 / 69 ]\n",
            "Processing Sub Dir 17 [ 60 / 69 ]\n",
            "Processing Sub Dir 73 [ 61 / 69 ]\n",
            "Processing Sub Dir 37 [ 62 / 69 ]\n",
            "Processing Sub Dir 20 [ 63 / 69 ]\n",
            "Processing Sub Dir 72 [ 64 / 69 ]\n",
            "Processing Sub Dir 6 [ 65 / 69 ]\n",
            "Processing Sub Dir 53 [ 66 / 69 ]\n",
            "Processing Sub Dir 63 [ 67 / 69 ]\n",
            "Processing Sub Dir 34 [ 68 / 69 ]\n",
            "Processing Sub Dir 1 [ 69 / 69 ]\n",
            "\n",
            " Time 6.566239984999811\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abKERlabR9x7",
        "colab_type": "code",
        "outputId": "bff34f2c-b708-41d5-83d2-cf48383ec1e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1241
        }
      },
      "source": [
        "surf_train_feature_vec = [[], []]   \n",
        " \n",
        "print(\"SURF Training Data\")\n",
        "people = os.listdir(TRAIN_DATA)    \n",
        "\n",
        "\n",
        "i, total = 0,len(people)\n",
        "with Timer() as t:\n",
        "  for person in people:\n",
        "      i += 1\n",
        "      print(\"Processing Sub Dir\", person, \"[\", i , \"/\", total, \"]\" )\n",
        "\n",
        "      # get SURF Features\n",
        "      surf_histograms = generateHistograms(allSURF[person], surf_kmeans)\n",
        "      surf_train_feature_vec[0].extend(surf_histograms)\n",
        "      surf_train_feature_vec[1].extend([person] * len(surf_histograms))\n",
        "    \n",
        "print(\"\\n\", \"Time\", t.secs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SURF Training Data\n",
            "Processing Sub Dir 43 [ 1 / 69 ]\n",
            "Processing Sub Dir 66 [ 2 / 69 ]\n",
            "Processing Sub Dir 24 [ 3 / 69 ]\n",
            "Processing Sub Dir 8 [ 4 / 69 ]\n",
            "Processing Sub Dir 54 [ 5 / 69 ]\n",
            "Processing Sub Dir 22 [ 6 / 69 ]\n",
            "Processing Sub Dir 11 [ 7 / 69 ]\n",
            "Processing Sub Dir 76 [ 8 / 69 ]\n",
            "Processing Sub Dir 69 [ 9 / 69 ]\n",
            "Processing Sub Dir 74 [ 10 / 69 ]\n",
            "Processing Sub Dir 9 [ 11 / 69 ]\n",
            "Processing Sub Dir 13 [ 12 / 69 ]\n",
            "Processing Sub Dir 38 [ 13 / 69 ]\n",
            "Processing Sub Dir 81 [ 14 / 69 ]\n",
            "Processing Sub Dir 67 [ 15 / 69 ]\n",
            "Processing Sub Dir 55 [ 16 / 69 ]\n",
            "Processing Sub Dir 65 [ 17 / 69 ]\n",
            "Processing Sub Dir 41 [ 18 / 69 ]\n",
            "Processing Sub Dir 7 [ 19 / 69 ]\n",
            "Processing Sub Dir 45 [ 20 / 69 ]\n",
            "Processing Sub Dir 78 [ 21 / 69 ]\n",
            "Processing Sub Dir 50 [ 22 / 69 ]\n",
            "Processing Sub Dir 62 [ 23 / 69 ]\n",
            "Processing Sub Dir 44 [ 24 / 69 ]\n",
            "Processing Sub Dir 75 [ 25 / 69 ]\n",
            "Processing Sub Dir 60 [ 26 / 69 ]\n",
            "Processing Sub Dir 57 [ 27 / 69 ]\n",
            "Processing Sub Dir 40 [ 28 / 69 ]\n",
            "Processing Sub Dir 21 [ 29 / 69 ]\n",
            "Processing Sub Dir 15 [ 30 / 69 ]\n",
            "Processing Sub Dir 12 [ 31 / 69 ]\n",
            "Processing Sub Dir 61 [ 32 / 69 ]\n",
            "Processing Sub Dir 49 [ 33 / 69 ]\n",
            "Processing Sub Dir 77 [ 34 / 69 ]\n",
            "Processing Sub Dir 42 [ 35 / 69 ]\n",
            "Processing Sub Dir 48 [ 36 / 69 ]\n",
            "Processing Sub Dir 58 [ 37 / 69 ]\n",
            "Processing Sub Dir 3 [ 38 / 69 ]\n",
            "Processing Sub Dir 71 [ 39 / 69 ]\n",
            "Processing Sub Dir 46 [ 40 / 69 ]\n",
            "Processing Sub Dir 59 [ 41 / 69 ]\n",
            "Processing Sub Dir 52 [ 42 / 69 ]\n",
            "Processing Sub Dir 16 [ 43 / 69 ]\n",
            "Processing Sub Dir 36 [ 44 / 69 ]\n",
            "Processing Sub Dir 47 [ 45 / 69 ]\n",
            "Processing Sub Dir 79 [ 46 / 69 ]\n",
            "Processing Sub Dir 56 [ 47 / 69 ]\n",
            "Processing Sub Dir 2 [ 48 / 69 ]\n",
            "Processing Sub Dir 64 [ 49 / 69 ]\n",
            "Processing Sub Dir 39 [ 50 / 69 ]\n",
            "Processing Sub Dir 10 [ 51 / 69 ]\n",
            "Processing Sub Dir 68 [ 52 / 69 ]\n",
            "Processing Sub Dir 4 [ 53 / 69 ]\n",
            "Processing Sub Dir 5 [ 54 / 69 ]\n",
            "Processing Sub Dir 51 [ 55 / 69 ]\n",
            "Processing Sub Dir 80 [ 56 / 69 ]\n",
            "Processing Sub Dir 70 [ 57 / 69 ]\n",
            "Processing Sub Dir 33 [ 58 / 69 ]\n",
            "Processing Sub Dir 14 [ 59 / 69 ]\n",
            "Processing Sub Dir 17 [ 60 / 69 ]\n",
            "Processing Sub Dir 73 [ 61 / 69 ]\n",
            "Processing Sub Dir 37 [ 62 / 69 ]\n",
            "Processing Sub Dir 20 [ 63 / 69 ]\n",
            "Processing Sub Dir 72 [ 64 / 69 ]\n",
            "Processing Sub Dir 6 [ 65 / 69 ]\n",
            "Processing Sub Dir 53 [ 66 / 69 ]\n",
            "Processing Sub Dir 63 [ 67 / 69 ]\n",
            "Processing Sub Dir 34 [ 68 / 69 ]\n",
            "Processing Sub Dir 1 [ 69 / 69 ]\n",
            "\n",
            " Time 6.870205224000074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cm2-3Bd-Au3",
        "colab_type": "code",
        "outputId": "5b90475b-c51e-4be8-c720-d19638f5beb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1241
        }
      },
      "source": [
        " orb_train_feature_vec = [[], []]   \n",
        "\n",
        "print(\"ORB Training Data\")\n",
        "people = os.listdir(TRAIN_DATA)    \n",
        "\n",
        "i, total = 0,len(people)\n",
        "with Timer() as t:\n",
        "  for person in people:\n",
        "      i += 1\n",
        "      print(\"Processing Sub Dir\", person, \"[\", i , \"/\", total, \"]\" )\n",
        "\n",
        "      # get ORB Features\n",
        "      orb_histograms = generateHistograms(allORB[person], orb_kmeans)\n",
        "      orb_train_feature_vec[0].extend(orb_histograms)\n",
        "      orb_train_feature_vec[1].extend([person] * len(orb_histograms))\n",
        "    \n",
        "\n",
        "    \n",
        "print(\"\\n\", \"Time\", t.secs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ORB Training Data\n",
            "Processing Sub Dir 43 [ 1 / 69 ]\n",
            "Processing Sub Dir 66 [ 2 / 69 ]\n",
            "Processing Sub Dir 24 [ 3 / 69 ]\n",
            "Processing Sub Dir 8 [ 4 / 69 ]\n",
            "Processing Sub Dir 54 [ 5 / 69 ]\n",
            "Processing Sub Dir 22 [ 6 / 69 ]\n",
            "Processing Sub Dir 11 [ 7 / 69 ]\n",
            "Processing Sub Dir 76 [ 8 / 69 ]\n",
            "Processing Sub Dir 69 [ 9 / 69 ]\n",
            "Processing Sub Dir 74 [ 10 / 69 ]\n",
            "Processing Sub Dir 9 [ 11 / 69 ]\n",
            "Processing Sub Dir 13 [ 12 / 69 ]\n",
            "Processing Sub Dir 38 [ 13 / 69 ]\n",
            "Processing Sub Dir 81 [ 14 / 69 ]\n",
            "Processing Sub Dir 67 [ 15 / 69 ]\n",
            "Processing Sub Dir 55 [ 16 / 69 ]\n",
            "Processing Sub Dir 65 [ 17 / 69 ]\n",
            "Processing Sub Dir 41 [ 18 / 69 ]\n",
            "Processing Sub Dir 7 [ 19 / 69 ]\n",
            "Processing Sub Dir 45 [ 20 / 69 ]\n",
            "Processing Sub Dir 78 [ 21 / 69 ]\n",
            "Processing Sub Dir 50 [ 22 / 69 ]\n",
            "Processing Sub Dir 62 [ 23 / 69 ]\n",
            "Processing Sub Dir 44 [ 24 / 69 ]\n",
            "Processing Sub Dir 75 [ 25 / 69 ]\n",
            "Processing Sub Dir 60 [ 26 / 69 ]\n",
            "Processing Sub Dir 57 [ 27 / 69 ]\n",
            "Processing Sub Dir 40 [ 28 / 69 ]\n",
            "Processing Sub Dir 21 [ 29 / 69 ]\n",
            "Processing Sub Dir 15 [ 30 / 69 ]\n",
            "Processing Sub Dir 12 [ 31 / 69 ]\n",
            "Processing Sub Dir 61 [ 32 / 69 ]\n",
            "Processing Sub Dir 49 [ 33 / 69 ]\n",
            "Processing Sub Dir 77 [ 34 / 69 ]\n",
            "Processing Sub Dir 42 [ 35 / 69 ]\n",
            "Processing Sub Dir 48 [ 36 / 69 ]\n",
            "Processing Sub Dir 58 [ 37 / 69 ]\n",
            "Processing Sub Dir 3 [ 38 / 69 ]\n",
            "Processing Sub Dir 71 [ 39 / 69 ]\n",
            "Processing Sub Dir 46 [ 40 / 69 ]\n",
            "Processing Sub Dir 59 [ 41 / 69 ]\n",
            "Processing Sub Dir 52 [ 42 / 69 ]\n",
            "Processing Sub Dir 16 [ 43 / 69 ]\n",
            "Processing Sub Dir 36 [ 44 / 69 ]\n",
            "Processing Sub Dir 47 [ 45 / 69 ]\n",
            "Processing Sub Dir 79 [ 46 / 69 ]\n",
            "Processing Sub Dir 56 [ 47 / 69 ]\n",
            "Processing Sub Dir 2 [ 48 / 69 ]\n",
            "Processing Sub Dir 64 [ 49 / 69 ]\n",
            "Processing Sub Dir 39 [ 50 / 69 ]\n",
            "Processing Sub Dir 10 [ 51 / 69 ]\n",
            "Processing Sub Dir 68 [ 52 / 69 ]\n",
            "Processing Sub Dir 4 [ 53 / 69 ]\n",
            "Processing Sub Dir 5 [ 54 / 69 ]\n",
            "Processing Sub Dir 51 [ 55 / 69 ]\n",
            "Processing Sub Dir 80 [ 56 / 69 ]\n",
            "Processing Sub Dir 70 [ 57 / 69 ]\n",
            "Processing Sub Dir 33 [ 58 / 69 ]\n",
            "Processing Sub Dir 14 [ 59 / 69 ]\n",
            "Processing Sub Dir 17 [ 60 / 69 ]\n",
            "Processing Sub Dir 73 [ 61 / 69 ]\n",
            "Processing Sub Dir 37 [ 62 / 69 ]\n",
            "Processing Sub Dir 20 [ 63 / 69 ]\n",
            "Processing Sub Dir 72 [ 64 / 69 ]\n",
            "Processing Sub Dir 6 [ 65 / 69 ]\n",
            "Processing Sub Dir 53 [ 66 / 69 ]\n",
            "Processing Sub Dir 63 [ 67 / 69 ]\n",
            "Processing Sub Dir 34 [ 68 / 69 ]\n",
            "Processing Sub Dir 1 [ 69 / 69 ]\n",
            "\n",
            " Time 4.736499226000433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQyD31iSSPvr",
        "colab_type": "text"
      },
      "source": [
        "#### Prepare Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3pZQmbOTCXL",
        "colab_type": "code",
        "outputId": "7d48e344-5e3b-41b7-c350-d00391f30fcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1326
        }
      },
      "source": [
        "sift_test_feature_vec = [[], []] \n",
        "\n",
        "\n",
        "print(\"SIFT Test Data\")\n",
        "people = os.listdir(TEST_DATA) \n",
        "\n",
        "\n",
        "i, total = 0,len(people)\n",
        "with Timer() as t:\n",
        "  for person in people:\n",
        "\n",
        "      i += 1\n",
        "      print(\"Processing Sub Dir\", person, \"[\", i , \"/\", total, \"]\" )\n",
        "      \n",
        "      \n",
        "      crop_names = os.listdir(os.path.join(TEST_DATA, person))\n",
        "      crop_names = list(map(lambda x: os.path.join(TEST_DATA, person, x), crop_names)) \n",
        "      crops = [cv2.imread(x , cv2.IMREAD_GRAYSCALE) for x in crop_names ]\n",
        "      \n",
        "      # get SIFT Features\n",
        "      sift_desc = extractFeatures(crops, getSIFTfeatures)\n",
        "      \n",
        "      # get histograms\n",
        "      sift_histograms = generateHistograms(sift_desc, sift_kmeans)\n",
        "      sift_test_feature_vec[0].extend(sift_histograms)\n",
        "      sift_test_feature_vec[1].extend([person] * len(sift_histograms))\n",
        "    \n",
        "print(\"\\n\", \"Time\", t.secs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SIFT Test Data\n",
            "Processing Sub Dir 43 [ 1 / 69 ]\n",
            "Processing Sub Dir 22 [ 2 / 69 ]\n",
            "Processing Sub Dir 74 [ 3 / 69 ]\n",
            "Processing Sub Dir 11 [ 4 / 69 ]\n",
            "Processing Sub Dir 9 [ 5 / 69 ]\n",
            "Processing Sub Dir 8 [ 6 / 69 ]\n",
            "Processing Sub Dir 76 [ 7 / 69 ]\n",
            "Processing Sub Dir 69 [ 8 / 69 ]\n",
            "Processing Sub Dir 54 [ 9 / 69 ]\n",
            "Processing Sub Dir 24 [ 10 / 69 ]\n",
            "Processing Sub Dir 78 [ 11 / 69 ]\n",
            "Processing Sub Dir 65 [ 12 / 69 ]\n",
            "Processing Sub Dir 67 [ 13 / 69 ]\n",
            "Processing Sub Dir 55 [ 14 / 69 ]\n",
            "Processing Sub Dir 81 [ 15 / 69 ]\n",
            "Processing Sub Dir 13 [ 16 / 69 ]\n",
            "Processing Sub Dir 66 [ 17 / 69 ]\n",
            "Processing Sub Dir 7 [ 18 / 69 ]\n",
            "Processing Sub Dir 38 [ 19 / 69 ]\n",
            "Processing Sub Dir 41 [ 20 / 69 ]\n",
            "Processing Sub Dir 40 [ 21 / 69 ]\n",
            "Processing Sub Dir 45 [ 22 / 69 ]\n",
            "Processing Sub Dir 15 [ 23 / 69 ]\n",
            "Processing Sub Dir 12 [ 24 / 69 ]\n",
            "Processing Sub Dir 75 [ 25 / 69 ]\n",
            "Processing Sub Dir 60 [ 26 / 69 ]\n",
            "Processing Sub Dir 50 [ 27 / 69 ]\n",
            "Processing Sub Dir 21 [ 28 / 69 ]\n",
            "Processing Sub Dir 57 [ 29 / 69 ]\n",
            "Processing Sub Dir 44 [ 30 / 69 ]\n",
            "Processing Sub Dir 3 [ 31 / 69 ]\n",
            "Processing Sub Dir 49 [ 32 / 69 ]\n",
            "Processing Sub Dir 48 [ 33 / 69 ]\n",
            "Processing Sub Dir 58 [ 34 / 69 ]\n",
            "Processing Sub Dir 59 [ 35 / 69 ]\n",
            "Processing Sub Dir 61 [ 36 / 69 ]\n",
            "Processing Sub Dir 62 [ 37 / 69 ]\n",
            "Processing Sub Dir 71 [ 38 / 69 ]\n",
            "Processing Sub Dir 42 [ 39 / 69 ]\n",
            "Processing Sub Dir 77 [ 40 / 69 ]\n",
            "Processing Sub Dir 47 [ 41 / 69 ]\n",
            "Processing Sub Dir 39 [ 42 / 69 ]\n",
            "Processing Sub Dir 56 [ 43 / 69 ]\n",
            "Processing Sub Dir 64 [ 44 / 69 ]\n",
            "Processing Sub Dir 46 [ 45 / 69 ]\n",
            "Processing Sub Dir 36 [ 46 / 69 ]\n",
            "Processing Sub Dir 16 [ 47 / 69 ]\n",
            "Processing Sub Dir 2 [ 48 / 69 ]\n",
            "Processing Sub Dir 10 [ 49 / 69 ]\n",
            "Processing Sub Dir 79 [ 50 / 69 ]\n",
            "Processing Sub Dir 73 [ 51 / 69 ]\n",
            "Processing Sub Dir 5 [ 52 / 69 ]\n",
            "Processing Sub Dir 4 [ 53 / 69 ]\n",
            "Processing Sub Dir 17 [ 54 / 69 ]\n",
            "Processing Sub Dir 14 [ 55 / 69 ]\n",
            "Processing Sub Dir 52 [ 56 / 69 ]\n",
            "Processing Sub Dir 33 [ 57 / 69 ]\n",
            "Processing Sub Dir 70 [ 58 / 69 ]\n",
            "Processing Sub Dir 80 [ 59 / 69 ]\n",
            "Processing Sub Dir 51 [ 60 / 69 ]\n",
            "Processing Sub Dir 72 [ 61 / 69 ]\n",
            "Processing Sub Dir 34 [ 62 / 69 ]\n",
            "Processing Sub Dir 6 [ 63 / 69 ]\n",
            "Processing Sub Dir 20 [ 64 / 69 ]\n",
            "Processing Sub Dir 1 [ 65 / 69 ]\n",
            "Processing Sub Dir 68 [ 66 / 69 ]\n",
            "Processing Sub Dir 37 [ 67 / 69 ]\n",
            "Processing Sub Dir 53 [ 68 / 69 ]\n",
            "Processing Sub Dir 63 [ 69 / 69 ]\n",
            "\n",
            " Time 839.8382625289996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOXcuCNzTCl2",
        "colab_type": "code",
        "outputId": "910542ac-85ac-481f-ce62-2e28781bfff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2461
        }
      },
      "source": [
        "surf_test_feature_vec = [[], []] \n",
        "\n",
        "\n",
        "print(\"SURF Test Data\")\n",
        "people = os.listdir(TEST_DATA) \n",
        "\n",
        "i, total = 0,len(people)\n",
        "with Timer() as t:\n",
        "  for person in people:\n",
        "\n",
        "      i += 1\n",
        "      print(\"Processing Sub Dir\", person, \"[\", i , \"/\", total, \"]\")\n",
        "       \n",
        "      crop_names = os.listdir(os.path.join(TEST_DATA, person))\n",
        "      crop_names = list(map(lambda x: os.path.join(TEST_DATA, person, x), crop_names)) \n",
        "      crops = [cv2.imread(x , cv2.IMREAD_GRAYSCALE) for x in crop_names ]\n",
        "            \n",
        "      # get SURFT Features\n",
        "      surf_desc = extractFeatures(crops, getSURFfeatures)\n",
        "\n",
        "      # get SURF Features\n",
        "      surf_histograms = generateHistograms(surf_desc, surf_kmeans)\n",
        "      surf_test_feature_vec[0].extend(surf_histograms)\n",
        "      surf_test_feature_vec[1].extend([person] * len(surf_histograms))\n",
        "      print(\"Extracted SURF\")\n",
        "    \n",
        "        \n",
        "print(\"\\n\", \"Time\", t.secs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SURF Test Data\n",
            "Processing Sub Dir 43 [ 1 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 22 [ 2 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 74 [ 3 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 11 [ 4 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 9 [ 5 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 8 [ 6 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 76 [ 7 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 69 [ 8 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 54 [ 9 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 24 [ 10 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 78 [ 11 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 65 [ 12 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 67 [ 13 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 55 [ 14 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 81 [ 15 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 13 [ 16 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 66 [ 17 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 7 [ 18 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 38 [ 19 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 41 [ 20 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 40 [ 21 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 45 [ 22 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 15 [ 23 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 12 [ 24 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 75 [ 25 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 60 [ 26 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 50 [ 27 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 21 [ 28 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 57 [ 29 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 44 [ 30 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 3 [ 31 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 49 [ 32 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 48 [ 33 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 58 [ 34 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 59 [ 35 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 61 [ 36 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 62 [ 37 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 71 [ 38 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 42 [ 39 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 77 [ 40 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 47 [ 41 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 39 [ 42 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 56 [ 43 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 64 [ 44 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 46 [ 45 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 36 [ 46 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 16 [ 47 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 2 [ 48 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 10 [ 49 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 79 [ 50 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 73 [ 51 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 5 [ 52 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 4 [ 53 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 17 [ 54 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 14 [ 55 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 52 [ 56 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 33 [ 57 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 70 [ 58 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 80 [ 59 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 51 [ 60 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 72 [ 61 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 34 [ 62 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 6 [ 63 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 20 [ 64 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 1 [ 65 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 68 [ 66 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 37 [ 67 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 53 [ 68 / 69 ]\n",
            "Extracted SURF\n",
            "Processing Sub Dir 63 [ 69 / 69 ]\n",
            "Extracted SURF\n",
            "\n",
            " Time 47.1190721210005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gMEFRTL-BlU",
        "colab_type": "code",
        "outputId": "cf87a49f-579d-48a9-c049-dac459f44151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1334
        }
      },
      "source": [
        "orb_test_feature_vec = [[], []]  \n",
        "\n",
        "\n",
        "print(\"ORB Test Data\")\n",
        "people = os.listdir(TEST_DATA) \n",
        "\n",
        "i, total = 0,len(people)\n",
        "with Timer() as t:\n",
        "  for person in people:\n",
        "\n",
        "      i += 1\n",
        "      print(\"Processing Sub Dir\", person, \"[\", i , \"/\", total, \"]\" )\n",
        "\n",
        "      crop_names = os.listdir(os.path.join(TEST_DATA, person))\n",
        "      crop_names = list(map(lambda x: os.path.join(TEST_DATA, person, x), crop_names)) \n",
        "      crops = [cv2.imread(x , cv2.IMREAD_GRAYSCALE) for x in crop_names ]\n",
        "      \n",
        "      # get ORB Features\n",
        "      orb_desc = extractFeatures(crops, getORBfeatures)\n",
        "            \n",
        "      # get ORB Features\n",
        "      orb_histograms = generateHistograms(orb_desc, orb_kmeans)\n",
        "      orb_test_feature_vec[0].extend(orb_histograms)\n",
        "      orb_test_feature_vec[1].extend([person] * len(orb_histograms))\n",
        "\n",
        "    \n",
        "    \n",
        "print(\"\\n\", \"Time\", t.secs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ORB Test Data\n",
            "Processing Sub Dir 43 [ 1 / 69 ]\n",
            "Processing Sub Dir 22 [ 2 / 69 ]\n",
            "Processing Sub Dir 74 [ 3 / 69 ]\n",
            "Processing Sub Dir 11 [ 4 / 69 ]\n",
            "Processing Sub Dir 9 [ 5 / 69 ]\n",
            "Processing Sub Dir 8 [ 6 / 69 ]\n",
            "Processing Sub Dir 76 [ 7 / 69 ]\n",
            "Processing Sub Dir 69 [ 8 / 69 ]\n",
            "Processing Sub Dir 54 [ 9 / 69 ]\n",
            "Processing Sub Dir 24 [ 10 / 69 ]\n",
            "Processing Sub Dir 78 [ 11 / 69 ]\n",
            "Processing Sub Dir 65 [ 12 / 69 ]\n",
            "Processing Sub Dir 67 [ 13 / 69 ]\n",
            "Processing Sub Dir 55 [ 14 / 69 ]\n",
            "Processing Sub Dir 81 [ 15 / 69 ]\n",
            "Processing Sub Dir 13 [ 16 / 69 ]\n",
            "Processing Sub Dir 66 [ 17 / 69 ]\n",
            "Processing Sub Dir 7 [ 18 / 69 ]\n",
            "No Features Extracted\n",
            "Processing Sub Dir 38 [ 19 / 69 ]\n",
            "Processing Sub Dir 41 [ 20 / 69 ]\n",
            "Processing Sub Dir 40 [ 21 / 69 ]\n",
            "Processing Sub Dir 45 [ 22 / 69 ]\n",
            "Processing Sub Dir 15 [ 23 / 69 ]\n",
            "Processing Sub Dir 12 [ 24 / 69 ]\n",
            "Processing Sub Dir 75 [ 25 / 69 ]\n",
            "Processing Sub Dir 60 [ 26 / 69 ]\n",
            "Processing Sub Dir 50 [ 27 / 69 ]\n",
            "Processing Sub Dir 21 [ 28 / 69 ]\n",
            "Processing Sub Dir 57 [ 29 / 69 ]\n",
            "Processing Sub Dir 44 [ 30 / 69 ]\n",
            "Processing Sub Dir 3 [ 31 / 69 ]\n",
            "No Features Extracted\n",
            "No Features Extracted\n",
            "Processing Sub Dir 49 [ 32 / 69 ]\n",
            "Processing Sub Dir 48 [ 33 / 69 ]\n",
            "Processing Sub Dir 58 [ 34 / 69 ]\n",
            "No Features Extracted\n",
            "Processing Sub Dir 59 [ 35 / 69 ]\n",
            "Processing Sub Dir 61 [ 36 / 69 ]\n",
            "Processing Sub Dir 62 [ 37 / 69 ]\n",
            "Processing Sub Dir 71 [ 38 / 69 ]\n",
            "Processing Sub Dir 42 [ 39 / 69 ]\n",
            "Processing Sub Dir 77 [ 40 / 69 ]\n",
            "Processing Sub Dir 47 [ 41 / 69 ]\n",
            "Processing Sub Dir 39 [ 42 / 69 ]\n",
            "Processing Sub Dir 56 [ 43 / 69 ]\n",
            "Processing Sub Dir 64 [ 44 / 69 ]\n",
            "Processing Sub Dir 46 [ 45 / 69 ]\n",
            "Processing Sub Dir 36 [ 46 / 69 ]\n",
            "Processing Sub Dir 16 [ 47 / 69 ]\n",
            "Processing Sub Dir 2 [ 48 / 69 ]\n",
            "Processing Sub Dir 10 [ 49 / 69 ]\n",
            "Processing Sub Dir 79 [ 50 / 69 ]\n",
            "Processing Sub Dir 73 [ 51 / 69 ]\n",
            "Processing Sub Dir 5 [ 52 / 69 ]\n",
            "Processing Sub Dir 4 [ 53 / 69 ]\n",
            "Processing Sub Dir 17 [ 54 / 69 ]\n",
            "Processing Sub Dir 14 [ 55 / 69 ]\n",
            "Processing Sub Dir 52 [ 56 / 69 ]\n",
            "Processing Sub Dir 33 [ 57 / 69 ]\n",
            "Processing Sub Dir 70 [ 58 / 69 ]\n",
            "Processing Sub Dir 80 [ 59 / 69 ]\n",
            "Processing Sub Dir 51 [ 60 / 69 ]\n",
            "Processing Sub Dir 72 [ 61 / 69 ]\n",
            "Processing Sub Dir 34 [ 62 / 69 ]\n",
            "Processing Sub Dir 6 [ 63 / 69 ]\n",
            "Processing Sub Dir 20 [ 64 / 69 ]\n",
            "Processing Sub Dir 1 [ 65 / 69 ]\n",
            "Processing Sub Dir 68 [ 66 / 69 ]\n",
            "Processing Sub Dir 37 [ 67 / 69 ]\n",
            "Processing Sub Dir 53 [ 68 / 69 ]\n",
            "Processing Sub Dir 63 [ 69 / 69 ]\n",
            "\n",
            " Time 12.078418099000373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3keABhDV5in",
        "colab_type": "text"
      },
      "source": [
        "#### Train SVM Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVu-nbHMV8Hs",
        "colab_type": "code",
        "outputId": "b2ba2c33-3fec-4cb8-8637-46f558657ab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "print(\"Training SIFT SVM\")\n",
        "svmSIFT = svm.SVC(gamma = 'auto')\n",
        "svmSIFT.fit(sift_train_feature_vec[0], sift_train_feature_vec[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training SIFT SVM\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
              "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "  tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH-At-PAV8VH",
        "colab_type": "code",
        "outputId": "564f888d-493a-4bf5-ac09-00d8a912a9ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "print(\"Training SURF SVM\")\n",
        "svmSURF = svm.SVC(gamma = 'auto')\n",
        "svmSURF.fit(surf_train_feature_vec[0], surf_train_feature_vec[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training SURF SVM\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
              "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "  tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2L9DkMtGHO5",
        "colab_type": "code",
        "outputId": "ae7040dc-3ede-436a-a6d4-af5cc657cfa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "print(\"Training  ORB SVM\")\n",
        "svmORB = svm.SVC(gamma = 'auto')\n",
        "svmORB.fit(orb_train_feature_vec[0], orb_train_feature_vec[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training  ORB SVM\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
              "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "  tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XivJ-crCWFGP",
        "colab_type": "text"
      },
      "source": [
        "#### Train MLP Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOpRM6TIWJzF",
        "colab_type": "code",
        "outputId": "af5f0a56-45e0-4102-bf35-8a2f2cf1233d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1199
        }
      },
      "source": [
        "print(\"Training SIFT MLP\")\n",
        "mlpSIFT = MLPClassifier(verbose=True, early_stopping=True, alpha=0.05, max_iter=600)\n",
        "mlpSIFT.fit(sift_train_feature_vec[0], sift_train_feature_vec[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training SIFT MLP\n",
            "Iteration 1, loss = 4.08721274\n",
            "Validation score: 0.215292\n",
            "Iteration 2, loss = 3.28826112\n",
            "Validation score: 0.547284\n",
            "Iteration 3, loss = 2.28818451\n",
            "Validation score: 0.800805\n",
            "Iteration 4, loss = 1.46012572\n",
            "Validation score: 0.879276\n",
            "Iteration 5, loss = 0.95734813\n",
            "Validation score: 0.905433\n",
            "Iteration 6, loss = 0.67365199\n",
            "Validation score: 0.921529\n",
            "Iteration 7, loss = 0.50482132\n",
            "Validation score: 0.933602\n",
            "Iteration 8, loss = 0.39770069\n",
            "Validation score: 0.943662\n",
            "Iteration 9, loss = 0.32698163\n",
            "Validation score: 0.945674\n",
            "Iteration 10, loss = 0.27771535\n",
            "Validation score: 0.955734\n",
            "Iteration 11, loss = 0.24089909\n",
            "Validation score: 0.957746\n",
            "Iteration 12, loss = 0.21449265\n",
            "Validation score: 0.963783\n",
            "Iteration 13, loss = 0.19396514\n",
            "Validation score: 0.965795\n",
            "Iteration 14, loss = 0.17827019\n",
            "Validation score: 0.965795\n",
            "Iteration 15, loss = 0.16575232\n",
            "Validation score: 0.965795\n",
            "Iteration 16, loss = 0.15536163\n",
            "Validation score: 0.965795\n",
            "Iteration 17, loss = 0.14724885\n",
            "Validation score: 0.975855\n",
            "Iteration 18, loss = 0.14028000\n",
            "Validation score: 0.973843\n",
            "Iteration 19, loss = 0.13418095\n",
            "Validation score: 0.969819\n",
            "Iteration 20, loss = 0.12919313\n",
            "Validation score: 0.971831\n",
            "Iteration 21, loss = 0.12499011\n",
            "Validation score: 0.975855\n",
            "Iteration 22, loss = 0.12124465\n",
            "Validation score: 0.973843\n",
            "Iteration 23, loss = 0.11804399\n",
            "Validation score: 0.973843\n",
            "Iteration 24, loss = 0.11518237\n",
            "Validation score: 0.973843\n",
            "Iteration 25, loss = 0.11275290\n",
            "Validation score: 0.973843\n",
            "Iteration 26, loss = 0.11052813\n",
            "Validation score: 0.973843\n",
            "Iteration 27, loss = 0.10865715\n",
            "Validation score: 0.971831\n",
            "Iteration 28, loss = 0.10677942\n",
            "Validation score: 0.971831\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.05, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "       learning_rate_init=0.001, max_iter=600, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
              "       validation_fraction=0.1, verbose=True, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEhtcfi_WJ8F",
        "colab_type": "code",
        "outputId": "8b7f768c-afa0-4286-f368-6796b3e610ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1122
        }
      },
      "source": [
        "print(\"Training SURF MLP\")\n",
        "mlpSURF = MLPClassifier(verbose=True, early_stopping=True, alpha=0.05, max_iter=600)\n",
        "mlpSURF.fit(surf_train_feature_vec[0], surf_train_feature_vec[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training SURF MLP\n",
            "Iteration 1, loss = 4.08640603\n",
            "Validation score: 0.221328\n",
            "Iteration 2, loss = 3.18045487\n",
            "Validation score: 0.567404\n",
            "Iteration 3, loss = 2.24556891\n",
            "Validation score: 0.782696\n",
            "Iteration 4, loss = 1.54396403\n",
            "Validation score: 0.885312\n",
            "Iteration 5, loss = 1.09231770\n",
            "Validation score: 0.923541\n",
            "Iteration 6, loss = 0.79181897\n",
            "Validation score: 0.941650\n",
            "Iteration 7, loss = 0.59233543\n",
            "Validation score: 0.949698\n",
            "Iteration 8, loss = 0.46623101\n",
            "Validation score: 0.959759\n",
            "Iteration 9, loss = 0.37213985\n",
            "Validation score: 0.959759\n",
            "Iteration 10, loss = 0.30684163\n",
            "Validation score: 0.963783\n",
            "Iteration 11, loss = 0.26318324\n",
            "Validation score: 0.965795\n",
            "Iteration 12, loss = 0.22633727\n",
            "Validation score: 0.967807\n",
            "Iteration 13, loss = 0.20022225\n",
            "Validation score: 0.967807\n",
            "Iteration 14, loss = 0.18043190\n",
            "Validation score: 0.969819\n",
            "Iteration 15, loss = 0.16447264\n",
            "Validation score: 0.973843\n",
            "Iteration 16, loss = 0.15206932\n",
            "Validation score: 0.973843\n",
            "Iteration 17, loss = 0.14215722\n",
            "Validation score: 0.977867\n",
            "Iteration 18, loss = 0.13385092\n",
            "Validation score: 0.975855\n",
            "Iteration 19, loss = 0.12662056\n",
            "Validation score: 0.975855\n",
            "Iteration 20, loss = 0.12094503\n",
            "Validation score: 0.977867\n",
            "Iteration 21, loss = 0.11631140\n",
            "Validation score: 0.975855\n",
            "Iteration 22, loss = 0.11170923\n",
            "Validation score: 0.977867\n",
            "Iteration 23, loss = 0.10812988\n",
            "Validation score: 0.977867\n",
            "Iteration 24, loss = 0.10502803\n",
            "Validation score: 0.977867\n",
            "Iteration 25, loss = 0.10222957\n",
            "Validation score: 0.977867\n",
            "Iteration 26, loss = 0.09985423\n",
            "Validation score: 0.977867\n",
            "Iteration 27, loss = 0.09771478\n",
            "Validation score: 0.977867\n",
            "Iteration 28, loss = 0.09590236\n",
            "Validation score: 0.977867\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.05, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "       learning_rate_init=0.001, max_iter=600, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
              "       validation_fraction=0.1, verbose=True, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANOVa_4p-dWI",
        "colab_type": "code",
        "outputId": "eac5da59-8928-469a-89ea-828248e1eb1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1904
        }
      },
      "source": [
        "print(\"Training ORB MLP\")\n",
        "mlpORB = MLPClassifier(verbose=True, early_stopping=True, alpha=0.05, max_iter=600)\n",
        "mlpORB.fit(orb_train_feature_vec[0], orb_train_feature_vec[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training ORB MLP\n",
            "Iteration 1, loss = 4.07284116\n",
            "Validation score: 0.171371\n",
            "Iteration 2, loss = 3.31789698\n",
            "Validation score: 0.411290\n",
            "Iteration 3, loss = 2.60059775\n",
            "Validation score: 0.590726\n",
            "Iteration 4, loss = 2.01083008\n",
            "Validation score: 0.681452\n",
            "Iteration 5, loss = 1.58579738\n",
            "Validation score: 0.745968\n",
            "Iteration 6, loss = 1.28228323\n",
            "Validation score: 0.802419\n",
            "Iteration 7, loss = 1.06107389\n",
            "Validation score: 0.834677\n",
            "Iteration 8, loss = 0.89320661\n",
            "Validation score: 0.844758\n",
            "Iteration 9, loss = 0.76466211\n",
            "Validation score: 0.852823\n",
            "Iteration 10, loss = 0.66246509\n",
            "Validation score: 0.872984\n",
            "Iteration 11, loss = 0.58393836\n",
            "Validation score: 0.883065\n",
            "Iteration 12, loss = 0.51801393\n",
            "Validation score: 0.893145\n",
            "Iteration 13, loss = 0.46353554\n",
            "Validation score: 0.897177\n",
            "Iteration 14, loss = 0.41908319\n",
            "Validation score: 0.907258\n",
            "Iteration 15, loss = 0.38108849\n",
            "Validation score: 0.907258\n",
            "Iteration 16, loss = 0.34993804\n",
            "Validation score: 0.913306\n",
            "Iteration 17, loss = 0.32495015\n",
            "Validation score: 0.917339\n",
            "Iteration 18, loss = 0.30092699\n",
            "Validation score: 0.917339\n",
            "Iteration 19, loss = 0.28123950\n",
            "Validation score: 0.923387\n",
            "Iteration 20, loss = 0.26437092\n",
            "Validation score: 0.921371\n",
            "Iteration 21, loss = 0.24978745\n",
            "Validation score: 0.923387\n",
            "Iteration 22, loss = 0.23682979\n",
            "Validation score: 0.923387\n",
            "Iteration 23, loss = 0.22582819\n",
            "Validation score: 0.925403\n",
            "Iteration 24, loss = 0.21632852\n",
            "Validation score: 0.927419\n",
            "Iteration 25, loss = 0.20776723\n",
            "Validation score: 0.927419\n",
            "Iteration 26, loss = 0.20034297\n",
            "Validation score: 0.929435\n",
            "Iteration 27, loss = 0.19330547\n",
            "Validation score: 0.931452\n",
            "Iteration 28, loss = 0.18755868\n",
            "Validation score: 0.931452\n",
            "Iteration 29, loss = 0.18192395\n",
            "Validation score: 0.933468\n",
            "Iteration 30, loss = 0.17692970\n",
            "Validation score: 0.931452\n",
            "Iteration 31, loss = 0.17269067\n",
            "Validation score: 0.931452\n",
            "Iteration 32, loss = 0.16874674\n",
            "Validation score: 0.931452\n",
            "Iteration 33, loss = 0.16528041\n",
            "Validation score: 0.931452\n",
            "Iteration 34, loss = 0.16183274\n",
            "Validation score: 0.931452\n",
            "Iteration 35, loss = 0.15886992\n",
            "Validation score: 0.933468\n",
            "Iteration 36, loss = 0.15607769\n",
            "Validation score: 0.935484\n",
            "Iteration 37, loss = 0.15368846\n",
            "Validation score: 0.933468\n",
            "Iteration 38, loss = 0.15142603\n",
            "Validation score: 0.933468\n",
            "Iteration 39, loss = 0.14922277\n",
            "Validation score: 0.933468\n",
            "Iteration 40, loss = 0.14715508\n",
            "Validation score: 0.937500\n",
            "Iteration 41, loss = 0.14539578\n",
            "Validation score: 0.935484\n",
            "Iteration 42, loss = 0.14360256\n",
            "Validation score: 0.935484\n",
            "Iteration 43, loss = 0.14199491\n",
            "Validation score: 0.933468\n",
            "Iteration 44, loss = 0.14051716\n",
            "Validation score: 0.935484\n",
            "Iteration 45, loss = 0.13907885\n",
            "Validation score: 0.931452\n",
            "Iteration 46, loss = 0.13782741\n",
            "Validation score: 0.933468\n",
            "Iteration 47, loss = 0.13649410\n",
            "Validation score: 0.931452\n",
            "Iteration 48, loss = 0.13530652\n",
            "Validation score: 0.931452\n",
            "Iteration 49, loss = 0.13415703\n",
            "Validation score: 0.931452\n",
            "Iteration 50, loss = 0.13306380\n",
            "Validation score: 0.931452\n",
            "Iteration 51, loss = 0.13202464\n",
            "Validation score: 0.929435\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.05, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "       learning_rate_init=0.001, max_iter=600, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
              "       validation_fraction=0.1, verbose=True, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSFhT0zPiZjZ",
        "colab_type": "text"
      },
      "source": [
        "#### Train Set Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEkyeUq3Caig",
        "colab_type": "code",
        "outputId": "18e68a01-b030-42fd-c32b-8f4c1c57cded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "## Training Predictions\n",
        "\n",
        "#%% Predict  SVM\n",
        "svmPredsSIFT = svmSIFT.predict(sift_train_feature_vec[0])\n",
        "print(\"SIFT SCORE (SVM)\", accuracy_score(sift_train_feature_vec[1], svmPredsSIFT))\n",
        "\n",
        "svmPredsSURF = svmSURF.predict(surf_train_feature_vec[0])\n",
        "print(\"SURF SCORE (SVM)\", accuracy_score(surf_train_feature_vec[1], svmPredsSURF))\n",
        "\n",
        "svmPredsORB = svmORB.predict(orb_train_feature_vec[0])\n",
        "print(\"ORB SCORE (SVM)\", accuracy_score(orb_train_feature_vec[1], svmPredsORB))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SIFT SCORE (SVM) 0.9853059581320451\n",
            "SURF SCORE (SVM) 0.9897342995169082\n",
            "ORB SCORE (SVM) 0.9244749596122779\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asReBijxWqdQ",
        "colab_type": "code",
        "outputId": "ee99d9be-75fb-41ad-99f3-4bc196e402dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#%% Predict Train MLP\n",
        "mlpPredsSIFT = mlpSIFT.predict(sift_train_feature_vec[0])\n",
        "print(\"SIFT SCORE (MLP)\", accuracy_score(sift_train_feature_vec[1], mlpPredsSIFT))\n",
        "\n",
        "mlpPredsSURF = mlpSURF.predict(surf_train_feature_vec[0])\n",
        "print(\"SURF SCORE (MLP)\",  accuracy_score(surf_train_feature_vec[1], mlpPredsSURF))\n",
        "\n",
        "mlpPredsORB = mlpORB.predict(orb_train_feature_vec[0])\n",
        "print(\"ORB SCORE (MLP)\", accuracy_score(orb_train_feature_vec[1], mlpPredsORB))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SIFT SCORE (MLP) 0.9945652173913043\n",
            "SURF SCORE (MLP) 0.9961755233494364\n",
            "ORB SCORE (MLP) 0.9894991922455574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OufSnp16n_7W",
        "colab_type": "text"
      },
      "source": [
        "#### Test Set Evalution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_654kOQ_wNw",
        "colab_type": "code",
        "outputId": "eb45caa7-325c-48d2-96ca-5b7160f8b440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Test Predictions\n",
        "\n",
        "#%% Predict SVM \n",
        "svmPredsSIFT = svmSIFT.predict(sift_test_feature_vec[0])\n",
        "print(\"SIFT SCORE (SVM)\", accuracy_score(sift_test_feature_vec[1], svmPredsSIFT))\n",
        "\n",
        "svmPredsSURF = svmSURF.predict(surf_test_feature_vec[0])\n",
        "print(\"SURF SCORE (SVM)\", accuracy_score(surf_test_feature_vec[1], svmPredsSURF))\n",
        "\n",
        "svmPredsORB = svmORB.predict(orb_test_feature_vec[0])\n",
        "print(\"ORB SCORE (SVM)\", accuracy_score(orb_test_feature_vec[1], svmPredsORB))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SIFT SCORE (SVM) 0.959794296400187\n",
            "SURF SCORE (SVM) 0.9630668536699393\n",
            "ORB SCORE (SVM) 0.8805620608899297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwaiqMOnW3dC",
        "colab_type": "code",
        "outputId": "de901033-2ab5-4d54-8a43-8b61eaed84bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#%% Predict Test MLP\n",
        "mlpPredsSIFT = mlpSIFT.predict(sift_test_feature_vec[0])\n",
        "print(\"SIFT SCORE (MLP)\", accuracy_score(sift_test_feature_vec[1], mlpPredsSIFT))\n",
        "\n",
        "mlpPredsSURF = mlpSURF.predict(surf_test_feature_vec[0])\n",
        "print(\"SURF SCORE (MLP)\",  accuracy_score(surf_test_feature_vec[1], mlpPredsSURF))\n",
        "\n",
        "mlpPredsORB = mlpORB.predict(orb_test_feature_vec[0])\n",
        "print(\"ORB SCORE (MLP)\", accuracy_score(orb_test_feature_vec[1], mlpPredsORB))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SIFT SCORE (MLP) 0.9780271154745208\n",
            "SURF SCORE (MLP) 0.9733520336605891\n",
            "ORB SCORE (MLP) 0.9311475409836065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXcLQ8qEigjl",
        "colab_type": "text"
      },
      "source": [
        "#### Save Models & Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS4JYwVzimOV",
        "colab_type": "code",
        "outputId": "724fcf59-0212-4c57-e251-f13fc96b314c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/drive/My\\ Drive/City\\ Msc\\ Data\\ Science/ComputerVision/models/v3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/City Msc Data Science/ComputerVision/models/v3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-p5QovMFLkK",
        "colab_type": "code",
        "outputId": "0aec0df7-a8ec-49d7-84da-e9b1f1f3b6cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## Save models\n",
        "joblib.dump(svmSIFT, \"model_siftSVM.pkl\")\n",
        "joblib.dump(svmSURF, \"model_surfSVM.pkl\")\n",
        "joblib.dump(svmORB, \"model_orbSVM.pkl\")\n",
        "\n",
        "joblib.dump(mlpSIFT, \"model_siftMLP.pkl\")\n",
        "joblib.dump(mlpSURF, \"model_surfMLP.pkl\")\n",
        "joblib.dump(mlpORB, \"model_orbMLP.pkl\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model_orbMLP.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F3_APTxUaJM",
        "colab_type": "code",
        "outputId": "b7be3262-6f9c-4860-de32-664d3a2c01ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Save bag of features\n",
        "\n",
        "%cd /content/drive/My\\ Drive/City\\ Msc\\ Data\\ Science/ComputerVision/models/v3\n",
        "\n",
        "joblib.dump(sift_kmeans, \"siftBAG_kmeans.pkl\")\n",
        "joblib.dump(surf_kmeans, \"surfBAG_kmeans.pkl\")\n",
        "joblib.dump(orb_kmeans, \"orbBAG_kmeans.pkl\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/City Msc Data Science/ComputerVision/models/v3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['orbBAG_kmeans.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpa0oz8bAk8S",
        "colab_type": "code",
        "outputId": "4f5d3606-5a7d-4ddc-c9a0-118215429db9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "## Save descriptors\n",
        "\n",
        "%cd /content/drive/My\\ Drive/City\\ Msc\\ Data\\ Science/ComputerVision/descriptors/v3\n",
        "\n",
        "\n",
        "joblib.dump(sift_train_feature_vec, \"sift_train.pkl\")\n",
        "joblib.dump(surf_train_feature_vec, \"surf_train.pkl\")\n",
        "joblib.dump(orb_train_feature_vec, \"orb_train.pkl\")\n",
        "\n",
        "\n",
        "joblib.dump(sift_test_feature_vec, \"sift_test.pkl\")\n",
        "joblib.dump(surf_test_feature_vec, \"surf_test.pkl\")\n",
        "joblib.dump(orb_test_feature_vec, \"orb_test.pkl\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/City Msc Data Science/ComputerVision/descriptors/v3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['orb_test.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXUAe5tWHqpt",
        "colab_type": "text"
      },
      "source": [
        "# Part 2: CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vojlse7X-Tpu",
        "colab_type": "code",
        "outputId": "43c1b441-c102-4cd7-8042-283b22882da7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1105
        }
      },
      "source": [
        "!pip install tensorflow-gpu\n",
        "!pip install --upgrade tensorflow\n",
        "!pip install numpy scipy\n",
        "!pip install scikit-learn\n",
        "!pip install pillow\n",
        "!pip install h5py\n",
        "!pip install keras\n",
        "!pip install keras-preprocessing\n",
        "!pip install h5py  #for saving keras models to disk?\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.13.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.7.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.16.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.7)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.9)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.13.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu) (2.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu) (40.9.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu) (0.15.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu) (3.1)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu) (5.1.3)\n",
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.1)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.16.3)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.7)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.9)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (40.9.0)\n",
            "Requirement already satisfied, skipping upgrade: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.15.2)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (5.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.16.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.2.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow) (0.46)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.16.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.16.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing in /usr/local/lib/python3.6/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras-preprocessing) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-preprocessing) (1.16.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.16.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJivnUQQizSl",
        "colab_type": "text"
      },
      "source": [
        "#### Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhR5MNzn8yxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0F9uIM9yoj0",
        "colab_type": "code",
        "outputId": "19e68e8f-d3e4-46c2-cf50-79045358ada6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "%cd /content/drive/My\\ Drive/City\\ Msc\\ Data\\ Science/ComputerVision/crops/\n",
        "!ls -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/City Msc Data Science/ComputerVision/crops\n",
            "total 19\n",
            "-rw-------  1 root root 6477 Apr 18 17:23  juan.jpg\n",
            "drwx------  2 root root 4096 Apr 22 16:35 'model(?)'\n",
            "drwx------ 71 root root 4096 Apr 16 18:53  test\n",
            "drwx------ 71 root root 4096 Apr 16 18:53  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0YMi9vsEhNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=False)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFthbhzo_e0H",
        "colab_type": "code",
        "outputId": "fd714d85-4bb3-4df3-e6ca-a7268c9e2a8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=r\"train/\",\n",
        "    target_size=(224, 224),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",\n",
        "  #  shuffle=True,\n",
        "    seed=42\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4968 images belonging to 69 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGoeoEdv_WDD",
        "colab_type": "code",
        "outputId": "7d49f69d-f256-4cdf-f619-2f164be15a3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "valid_generator = test_datagen.flow_from_directory(\n",
        "    directory=r\"test/\",\n",
        "    target_size=(224, 224),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",\n",
        "#    shuffle=True,\n",
        "    seed=42\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2139 images belonging to 69 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjRI2QiKwjXq",
        "colab_type": "text"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_piCEQ3DJlVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Flatten, Dropout\n",
        "from keras.applications import VGG16\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXDY0CULDp2c",
        "colab_type": "text"
      },
      "source": [
        "#### Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M76M8_yNR33",
        "colab_type": "code",
        "outputId": "fa37b583-00ad-46c0-9acf-b382f6743b8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "source": [
        "# Build CNN with VGG16 base architecture and ImageNet weights\n",
        "base_model=VGG16(weights='imagenet',include_top=False, input_shape=(224, 224, 3)) #imports the  VGG model and discards the last 1000 neuron layer.\n",
        "\n",
        "x=base_model.output\n",
        "x=Flatten()(x)\n",
        "x=Dense(1028,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x=Dropout(0.5)(x)\n",
        "preds=Dense(69,activation='softmax')(x) #final layer with softmax activation\n",
        "\n",
        "model= Model(inputs=base_model.input,outputs=preds)\n",
        "\n",
        "for layer in model.layers[:19]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[19:]:\n",
        "    layer.trainable=True\n",
        "\n",
        "for i,layer in enumerate(model.layers):\n",
        "  print(i,layer.name, layer.trainable)\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_3 False\n",
            "1 block1_conv1 False\n",
            "2 block1_conv2 False\n",
            "3 block1_pool False\n",
            "4 block2_conv1 False\n",
            "5 block2_conv2 False\n",
            "6 block2_pool False\n",
            "7 block3_conv1 False\n",
            "8 block3_conv2 False\n",
            "9 block3_conv3 False\n",
            "10 block3_pool False\n",
            "11 block4_conv1 False\n",
            "12 block4_conv2 False\n",
            "13 block4_conv3 False\n",
            "14 block4_pool False\n",
            "15 block5_conv1 False\n",
            "16 block5_conv2 False\n",
            "17 block5_conv3 False\n",
            "18 block5_pool False\n",
            "19 flatten_3 True\n",
            "20 dense_5 True\n",
            "21 dropout_3 True\n",
            "22 dense_6 True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGwMpu-uDtqI",
        "colab_type": "text"
      },
      "source": [
        "#### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHUrVGTFPsC_",
        "colab_type": "code",
        "outputId": "2bb343a3-0e65-4288-b8bf-85fab3cd7bcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        }
      },
      "source": [
        "# Train last 4 layers of model\n",
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "early_stop = EarlyStopping(patience=3)\n",
        "step_size_train=train_generator.n//train_generator.batch_size\n",
        "step_size_valid=valid_generator.n//valid_generator.batch_size\n",
        "\n",
        "with Timer() as t:\n",
        "  history = model.fit_generator(generator=train_generator,\n",
        "                     steps_per_epoch=step_size_train,\n",
        "                     validation_data=valid_generator,\n",
        "                     validation_steps=step_size_valid,\n",
        "                     callbacks=[early_stop],\n",
        "                     epochs=30)\n",
        "  \n",
        "print(\"\\n\", \"Time\", t.secs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "155/155 [==============================] - 73s 469ms/step - loss: 3.3950 - acc: 0.3589 - val_loss: 0.4705 - val_acc: 0.9568\n",
            "Epoch 2/30\n",
            "155/155 [==============================] - 68s 437ms/step - loss: 0.8322 - acc: 0.7962 - val_loss: 0.0977 - val_acc: 0.9910\n",
            "Epoch 3/30\n",
            "155/155 [==============================] - 67s 432ms/step - loss: 0.4349 - acc: 0.8917 - val_loss: 0.0609 - val_acc: 0.9943\n",
            "Epoch 4/30\n",
            "155/155 [==============================] - 66s 429ms/step - loss: 0.2866 - acc: 0.9315 - val_loss: 0.0369 - val_acc: 0.9953\n",
            "Epoch 5/30\n",
            "155/155 [==============================] - 68s 436ms/step - loss: 0.2265 - acc: 0.9464 - val_loss: 0.0223 - val_acc: 0.9972\n",
            "Epoch 6/30\n",
            "155/155 [==============================] - 67s 434ms/step - loss: 0.1828 - acc: 0.9500 - val_loss: 0.0152 - val_acc: 0.9972\n",
            "Epoch 7/30\n",
            "155/155 [==============================] - 68s 441ms/step - loss: 0.1776 - acc: 0.9506 - val_loss: 0.0177 - val_acc: 0.9972\n",
            "Epoch 8/30\n",
            "155/155 [==============================] - 67s 435ms/step - loss: 0.1713 - acc: 0.9524 - val_loss: 0.0128 - val_acc: 0.9986\n",
            "Epoch 9/30\n",
            "155/155 [==============================] - 68s 436ms/step - loss: 0.1615 - acc: 0.9548 - val_loss: 0.0082 - val_acc: 0.9986\n",
            "Epoch 10/30\n",
            "155/155 [==============================] - 69s 443ms/step - loss: 0.1453 - acc: 0.9593 - val_loss: 0.0154 - val_acc: 0.9972\n",
            "Epoch 11/30\n",
            "155/155 [==============================] - 67s 430ms/step - loss: 0.1616 - acc: 0.9504 - val_loss: 0.0098 - val_acc: 0.9976\n",
            "Epoch 12/30\n",
            "155/155 [==============================] - 67s 429ms/step - loss: 0.1406 - acc: 0.9579 - val_loss: 0.0074 - val_acc: 0.9986\n",
            "Epoch 13/30\n",
            "155/155 [==============================] - 67s 435ms/step - loss: 0.1212 - acc: 0.9591 - val_loss: 0.0076 - val_acc: 0.9986\n",
            "Epoch 14/30\n",
            "155/155 [==============================] - 69s 445ms/step - loss: 0.1289 - acc: 0.9577 - val_loss: 0.0107 - val_acc: 0.9972\n",
            "Epoch 15/30\n",
            "155/155 [==============================] - 68s 436ms/step - loss: 0.1988 - acc: 0.9335 - val_loss: 0.0181 - val_acc: 0.9972\n",
            "\n",
            " Time 1018.5284022610012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFYtwFi-D2Fo",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mx6UQnLj_xE",
        "colab_type": "code",
        "outputId": "565ccdf8-f4ff-457a-8cfd-9eaeb18b4ce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        }
      },
      "source": [
        "# Plot Accuracy and Loss\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QoFjcK7uNPe",
        "colab_type": "code",
        "outputId": "03ca7e8c-8e00-4de7-fc81-467f3478e9ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1272
        }
      },
      "source": [
        "# Get mapping  for predictions\n",
        "class_to_index = train_generator.class_indices\n",
        "label_map = dict((v,k) for k,v in class_to_index.items()) \n",
        "label_map"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '1',\n",
              " 1: '10',\n",
              " 2: '11',\n",
              " 3: '12',\n",
              " 4: '13',\n",
              " 5: '14',\n",
              " 6: '15',\n",
              " 7: '16',\n",
              " 8: '17',\n",
              " 9: '2',\n",
              " 10: '20',\n",
              " 11: '21',\n",
              " 12: '22',\n",
              " 13: '24',\n",
              " 14: '3',\n",
              " 15: '33',\n",
              " 16: '34',\n",
              " 17: '36',\n",
              " 18: '37',\n",
              " 19: '38',\n",
              " 20: '39',\n",
              " 21: '4',\n",
              " 22: '40',\n",
              " 23: '41',\n",
              " 24: '42',\n",
              " 25: '43',\n",
              " 26: '44',\n",
              " 27: '45',\n",
              " 28: '46',\n",
              " 29: '47',\n",
              " 30: '48',\n",
              " 31: '49',\n",
              " 32: '5',\n",
              " 33: '50',\n",
              " 34: '51',\n",
              " 35: '52',\n",
              " 36: '53',\n",
              " 37: '54',\n",
              " 38: '55',\n",
              " 39: '56',\n",
              " 40: '57',\n",
              " 41: '58',\n",
              " 42: '59',\n",
              " 43: '6',\n",
              " 44: '60',\n",
              " 45: '61',\n",
              " 46: '62',\n",
              " 47: '63',\n",
              " 48: '64',\n",
              " 49: '65',\n",
              " 50: '66',\n",
              " 51: '67',\n",
              " 52: '68',\n",
              " 53: '69',\n",
              " 54: '7',\n",
              " 55: '70',\n",
              " 56: '71',\n",
              " 57: '72',\n",
              " 58: '73',\n",
              " 59: '74',\n",
              " 60: '75',\n",
              " 61: '76',\n",
              " 62: '77',\n",
              " 63: '78',\n",
              " 64: '79',\n",
              " 65: '8',\n",
              " 66: '80',\n",
              " 67: '81',\n",
              " 68: '9'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IqJYar8Soxa",
        "colab_type": "code",
        "outputId": "65d08c70-695a-44a7-d61e-908cb882e2c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# Batch Predictions\n",
        "def get_classes(preds, label_map):\n",
        "  predictions = np.argmax(preds, axis=-1)\n",
        "  class_preds = [label_map[k] for k in predictions]\n",
        "  return class_preds\n",
        "\n",
        "test_probs = model.predict_generator(valid_generator, steps=step_size_valid)\n",
        "test_preds = get_classes(test_probs, label_map)\n",
        "print(test_preds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['9', '46', '3', '53', '76', '17', '59', '51', '79', '47', '41', '2', '20', '4', '1', '20', '59', '73', '49', '37', '12', '15', '38', '2', '55', '77', '41', '2', '47', '22', '3', '65', '50', '44', '24', '54', '47', '53', '22', '8', '44', '8', '3', '61', '75', '52', '43', '56', '49', '22', '54', '61', '52', '74', '48', '40', '15', '10', '9', '64', '36', '73', '77', '37', '7', '66', '74', '60', '53', '53', '38', '68', '45', '77', '54', '49', '70', '10', '48', '61', '22', '45', '63', '51', '3', '42', '12', '52', '64', '20', '68', '48', '10', '13', '41', '40', '81', '2', '73', '22', '65', '17', '47', '42', '38', '13', '71', '22', '58', '10', '61', '54', '44', '36', '49', '66', '2', '73', '24', '2', '22', '34', '73', '58', '59', '38', '44', '64', '7', '69', '56', '73', '5', '45', '16', '77', '59', '66', '41', '4', '6', '6', '2', '40', '10', '16', '2', '52', '45', '54', '48', '68', '70', '77', '61', '61', '81', '51', '72', '24', '9', '53', '7', '63', '20', '74', '21', '3', '5', '81', '75', '77', '40', '76', '69', '49', '75', '56', '60', '67', '48', '22', '51', '8', '42', '17', '22', '4', '61', '53', '55', '58', '1', '39', '3', '33', '15', '68', '60', '60', '52', '38', '66', '39', '38', '16', '57', '21', '4', '3', '20', '58', '40', '75', '55', '9', '41', '53', '8', '51', '74', '72', '78', '57', '60', '51', '68', '63', '67', '2', '41', '57', '44', '44', '69', '10', '47', '37', '74', '46', '73', '20', '59', '69', '38', '7', '1', '73', '14', '34', '44', '17', '5', '38', '22', '55', '12', '5', '11', '43', '24', '72', '3', '20', '67', '42', '37', '24', '56', '64', '21', '12', '7', '15', '58', '50', '2', '17', '67', '59', '13', '3', '74', '38', '60', '53', '16', '76', '78', '62', '44', '6', '4', '11', '55', '48', '37', '59', '16', '36', '79', '20', '50', '77', '81', '16', '42', '49', '80', '8', '61', '10', '71', '15', '59', '64', '6', '12', '64', '54', '43', '9', '58', '36', '79', '33', '54', '53', '43', '34', '69', '46', '22', '66', '52', '59', '42', '80', '50', '6', '55', '66', '45', '54', '41', '12', '69', '22', '16', '22', '10', '73', '47', '20', '79', '73', '52', '33', '49', '1', '11', '71', '53', '66', '48', '8', '47', '52', '60', '63', '72', '50', '13', '61', '45', '3', '5', '3', '34', '71', '68', '68', '65', '11', '17', '46', '36', '64', '65', '54', '80', '38', '80', '10', '73', '12', '53', '59', '77', '46', '52', '76', '64', '48', '53', '4', '15', '56', '41', '16', '57', '50', '2', '58', '7', '81', '65', '53', '13', '1', '53', '22', '66', '54', '6', '46', '43', '65', '4', '62', '72', '47', '56', '63', '13', '9', '55', '24', '10', '20', '69', '40', '16', '66', '12', '5', '39', '61', '21', '20', '41', '42', '40', '8', '7', '9', '1', '76', '61', '40', '14', '78', '11', '38', '52', '55', '78', '75', '14', '63', '50', '52', '15', '62', '62', '8', '80', '34', '67', '62', '75', '38', '44', '51', '36', '79', '69', '51', '81', '42', '58', '72', '37', '13', '55', '44', '50', '67', '67', '54', '13', '46', '37', '81', '22', '16', '22', '8', '42', '24', '36', '55', '43', '2', '34', '73', '38', '47', '17', '50', '15', '38', '10', '34', '47', '78', '53', '13', '70', '63', '72', '47', '78', '1', '12', '57', '11', '57', '45', '49', '48', '21', '10', '5', '69', '21', '71', '77', '1', '63', '54', '10', '80', '70', '3', '66', '9', '42', '53', '70', '66', '52', '59', '51', '58', '56', '61', '79', '17', '50', '49', '74', '49', '39', '14', '70', '55', '73', '24', '71', '7', '58', '68', '9', '77', '62', '56', '11', '21', '41', '42', '60', '54', '57', '45', '78', '41', '38', '64', '6', '12', '51', '41', '41', '78', '5', '71', '63', '7', '12', '11', '75', '14', '67', '45', '33', '42', '76', '56', '74', '36', '69', '54', '56', '75', '58', '62', '40', '41', '24', '59', '11', '81', '78', '49', '66', '81', '53', '56', '8', '57', '62', '6', '5', '72', '67', '81', '71', '51', '34', '10', '47', '76', '62', '81', '68', '37', '64', '78', '46', '24', '72', '38', '73', '67', '16', '2', '2', '50', '65', '81', '9', '72', '72', '34', '43', '2', '57', '65', '45', '40', '15', '21', '55', '24', '2', '41', '67', '21', '81', '66', '13', '11', '51', '67', '10', '60', '70', '21', '39', '2', '63', '37', '46', '4', '55', '63', '76', '48', '71', '17', '39', '52', '6', '49', '20', '42', '69', '48', '43', '11', '43', '15', '34', '80', '21', '80', '55', '38', '16', '14', '73', '9', '24', '69', '5', '12', '75', '44', '8', '49', '20', '12', '37', '51', '16', '60', '2', '62', '49', '42', '11', '68', '12', '51', '75', '57', '14', '64', '80', '53', '22', '12', '68', '69', '52', '22', '80', '20', '36', '63', '14', '56', '75', '46', '17', '58', '54', '59', '39', '43', '63', '72', '64', '16', '42', '58', '52', '52', '66', '7', '79', '14', '3', '64', '58', '17', '67', '6', '81', '37', '56', '48', '14', '73', '37', '50', '13', '17', '53', '70', '70', '52', '13', '72', '41', '40', '70', '71', '4', '56', '76', '70', '33', '47', '6', '33', '71', '65', '11', '63', '68', '72', '81', '75', '78', '9', '80', '4', '13', '77', '79', '60', '69', '20', '48', '47', '67', '60', '36', '70', '11', '20', '6', '1', '24', '56', '58', '8', '66', '51', '78', '81', '70', '24', '2', '74', '5', '61', '81', '72', '15', '72', '43', '50', '68', '5', '64', '1', '59', '5', '50', '34', '40', '53', '74', '76', '4', '46', '21', '56', '51', '34', '36', '75', '60', '78', '59', '56', '6', '12', '78', '56', '38', '37', '44', '48', '48', '9', '17', '47', '17', '16', '40', '67', '57', '57', '65', '77', '13', '12', '65', '81', '11', '4', '14', '51', '57', '47', '58', '8', '40', '7', '76', '34', '79', '37', '49', '8', '79', '78', '43', '6', '12', '57', '71', '68', '54', '1', '68', '36', '37', '24', '66', '64', '67', '65', '10', '24', '51', '54', '37', '59', '38', '12', '9', '16', '60', '4', '78', '1', '2', '39', '57', '62', '38', '62', '34', '63', '13', '40', '20', '49', '34', '39', '68', '1', '49', '7', '8', '54', '75', '45', '11', '44', '79', '54', '1', '65', '67', '58', '51', '71', '42', '20', '67', '75', '5', '71', '73', '61', '16', '8', '24', '11', '2', '46', '1', '57', '67', '36', '74', '38', '70', '77', '24', '44', '50', '76', '39', '33', '61', '1', '13', '46', '76', '16', '39', '5', '42', '10', '47', '34', '13', '62', '58', '5', '71', '79', '69', '13', '76', '75', '69', '3', '11', '57', '8', '1', '40', '4', '71', '10', '52', '21', '6', '80', '81', '17', '5', '66', '76', '52', '36', '74', '80', '33', '71', '81', '10', '49', '15', '76', '24', '57', '33', '67', '69', '14', '5', '12', '64', '56', '64', '45', '12', '78', '64', '4', '47', '6', '7', '40', '76', '81', '45', '56', '41', '53', '44', '67', '21', '11', '70', '62', '62', '24', '64', '39', '16', '76', '48', '21', '12', '80', '34', '71', '46', '34', '45', '62', '4', '43', '8', '13', '50', '9', '20', '2', '20', '56', '36', '9', '24', '56', '55', '74', '7', '57', '59', '78', '39', '59', '63', '58', '52', '9', '15', '55', '67', '62', '60', '13', '66', '64', '80', '40', '70', '37', '74', '80', '74', '36', '53', '10', '70', '55', '55', '9', '51', '3', '62', '49', '13', '36', '65', '57', '5', '4', '3', '12', '33', '49', '15', '52', '36', '63', '3', '57', '11', '66', '71', '79', '75', '46', '71', '39', '16', '40', '66', '41', '63', '66', '9', '4', '14', '48', '42', '66', '5', '40', '14', '60', '76', '48', '81', '44', '17', '16', '14', '7', '36', '81', '75', '36', '75', '47', '2', '58', '50', '21', '55', '69', '44', '15', '74', '75', '42', '38', '59', '81', '61', '15', '21', '54', '37', '61', '5', '6', '9', '10', '62', '17', '63', '43', '24', '65', '1', '65', '77', '57', '4', '52', '69', '62', '44', '58', '66', '46', '21', '5', '49', '43', '74', '67', '36', '76', '76', '54', '44', '46', '34', '5', '56', '33', '79', '49', '65', '76', '61', '7', '61', '78', '61', '54', '50', '80', '17', '37', '22', '13', '65', '10', '62', '21', '79', '54', '7', '43', '79', '33', '72', '72', '65', '46', '69', '6', '68', '34', '69', '58', '60', '12', '42', '43', '1', '67', '80', '42', '53', '17', '6', '1', '76', '66', '49', '7', '39', '4', '40', '21', '2', '1', '74', '40', '75', '59', '52', '46', '33', '64', '39', '43', '51', '73', '2', '4', '34', '43', '39', '39', '70', '16', '33', '5', '7', '3', '17', '79', '71', '4', '11', '47', '70', '57', '65', '33', '75', '22', '21', '53', '11', '8', '39', '8', '72', '5', '42', '70', '77', '76', '64', '7', '47', '74', '70', '51', '58', '69', '45', '11', '46', '63', '60', '44', '14', '60', '51', '81', '20', '3', '42', '14', '34', '38', '59', '7', '62', '3', '72', '37', '3', '51', '3', '37', '75', '37', '15', '55', '10', '80', '7', '53', '45', '55', '73', '71', '78', '17', '41', '36', '42', '68', '9', '40', '11', '8', '68', '69', '72', '64', '54', '49', '39', '22', '45', '17', '44', '44', '16', '16', '61', '46', '48', '11', '12', '33', '69', '3', '45', '63', '9', '72', '75', '68', '69', '7', '20', '65', '74', '55', '3', '77', '41', '15', '71', '22', '1', '74', '55', '61', '24', '61', '21', '38', '43', '33', '16', '40', '21', '15', '73', '72', '51', '69', '1', '8', '56', '57', '48', '74', '58', '7', '41', '74', '65', '34', '64', '74', '60', '60', '15', '3', '48', '79', '9', '71', '49', '73', '42', '41', '74', '79', '62', '37', '22', '33', '70', '59', '68', '14', '67', '37', '8', '77', '48', '15', '9', '10', '62', '55', '13', '14', '80', '75', '17', '22', '21', '2', '41', '45', '33', '9', '46', '64', '14', '77', '5', '40', '6', '41', '63', '66', '22', '66', '81', '34', '54', '55', '9', '75', '21', '62', '72', '80', '16', '9', '43', '34', '55', '62', '58', '73', '69', '48', '67', '46', '36', '57', '70', '68', '45', '53', '51', '37', '40', '62', '63', '77', '73', '14', '71', '11', '12', '79', '43', '56', '45', '51', '53', '47', '75', '38', '77', '4', '4', '73', '80', '76', '77', '46', '8', '47', '69', '54', '73', '53', '60', '51', '70', '65', '76', '77', '7', '50', '68', '7', '20', '53', '62', '47', '49', '48', '24', '33', '45', '76', '13', '51', '59', '50', '62', '39', '1', '78', '39', '42', '60', '61', '68', '63', '33', '68', '33', '73', '77', '57', '78', '64', '74', '41', '50', '1', '54', '71', '16', '48', '6', '24', '53', '51', '1', '6', '46', '67', '17', '17', '59', '63', '37', '50', '5', '46', '15', '21', '21', '13', '10', '60', '79', '49', '54', '14', '55', '64', '48', '22', '5', '7', '64', '63', '81', '67', '70', '79', '60', '16', '67', '81', '50', '12', '69', '65', '78', '80', '79', '14', '1', '34', '38', '33', '13', '44', '10', '33', '56', '15', '15', '60', '39', '24', '46', '66', '56', '57', '8', '11', '61', '6', '17', '36', '2', '75', '73', '3', '72', '70', '75', '34', '8', '44', '9', '52', '33', '68', '17', '77', '52', '13', '6', '43', '61', '70', '57', '41', '2', '46', '37', '38', '73', '42', '6', '44', '77', '16', '76', '39', '52', '58', '77', '43', '63', '50', '49', '78', '17', '37', '15', '61', '47', '22', '6', '74', '39', '80', '78', '38', '77', '72', '43', '16', '20', '20', '50', '10', '13', '33', '64', '5', '59', '24', '45', '4', '81', '65', '59', '37', '77', '14', '10', '68', '24', '12', '59', '6', '61', '48', '55', '72', '42', '67', '40', '14', '63', '66', '33', '11', '68', '14', '22', '78', '6', '36', '78', '52', '77', '71', '66', '13', '80', '79', '5', '66', '37', '36', '54', '7', '71', '81', '73', '58', '57', '81', '9', '47', '81', '77', '79', '36', '40', '4', '46', '5', '64', '80', '17', '68', '61', '52', '67', '80', '8', '63', '60', '47', '73', '68', '33', '8', '59', '67', '52', '64', '5', '65', '64', '34', '1', '37', '14', '64', '6', '59', '70', '40', '73', '21', '62', '16', '10', '54', '76', '61', '47', '76', '54', '43', '41', '53', '54', '43', '52', '2', '74', '61', '13', '37', '8', '7', '63', '10', '17', '50', '5', '45', '68', '11', '4', '36', '38', '21', '81', '11', '4', '69', '41', '66', '63', '64', '7', '55', '37', '60', '20', '40', '47', '24', '10', '1', '4', '53', '53', '52', '58', '66', '15', '3', '60', '68', '58', '49', '74', '7', '54', '79', '34', '80', '65', '37', '50', '17', '55', '51', '69', '20', '21', '16', '74', '41', '15', '63', '50', '69', '22', '43', '53', '55', '49', '7', '81', '24', '56', '44', '73', '22', '36', '49', '46', '14', '42', '70', '49', '46', '6', '39', '3', '64', '22', '73', '75', '71', '36', '34', '39', '56', '22', '61', '44', '51', '75', '61', '53', '46', '21', '52', '53', '12', '2', '21', '43', '20', '21', '1', '78', '75', '47', '41', '46', '70', '2', '77', '73', '60', '40', '3', '56', '61', '39', '50', '49', '66', '44', '49', '58', '20', '41', '53', '17', '43', '10', '79', '17', '62', '38', '7', '71', '17']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAiuEtytyZ94",
        "colab_type": "code",
        "outputId": "ee7fd42f-23b2-4b45-8606-2581b22b3fb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "# Indivdual Predictions\n",
        "def transform_img(img, show=False):\n",
        "    img = cv2.resize(img, (224,224))\n",
        "    img_tensor = np.expand_dims(img, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
        "    return img_tensor\n",
        "\n",
        "juan = cv2.imread(\"juan.jpg\")\n",
        "cv2_imshow(juan)\n",
        "\n",
        "juan_67 = transform_img(juan)\n",
        "pred = model.predict(juan_67)\n",
        "\n",
        "guess = get_classes(pred, label_map)\n",
        "print(guess)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAABYOUlEQVR4nK39Wa8kSZIeCsqmaou7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\npAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=128x128 at 0x7F1AF15F2AC8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "['17']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwQ4j3qxDlOU",
        "colab_type": "text"
      },
      "source": [
        "#### Save Models and Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piLMLNeZuHm9",
        "colab_type": "code",
        "outputId": "c3d3dc6c-505a-4b49-b701-fac3a12f7b9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Save Models and Data\n",
        "%cd /content/drive/My\\ Drive/City\\ Msc\\ Data\\ Science/ComputerVision/models/v3\n",
        "\n",
        "joblib.dump(label_map, 'cnn_labelmap.pkl')\n",
        "\n",
        "#python save\n",
        "joblib.dump(svmSIFT, \"model_VGG16.pkl\")\n",
        "\n",
        "#keras save\n",
        "model.save('model_VGG16.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/City Msc Data Science/ComputerVision/models/v3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7NDfnsUNSkZ",
        "colab_type": "text"
      },
      "source": [
        "# MobileNet (doesn't work)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNijaICz_kKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense,GlobalAveragePooling2D, Dropout, Flatten\n",
        "from keras.applications import MobileNet\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoU9c5NI4B3Y",
        "colab_type": "code",
        "outputId": "7f8252d6-e35e-4348-f0f8-05d4cb642a1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1564
        }
      },
      "source": [
        "base_model=MobileNet(weights='imagenet',include_top=False, input_shape=(224, 224, 3)) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
        "\n",
        "x=base_model.output\n",
        "x=Flatten()(x)\n",
        "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x=Dropout(0.5)(x)\n",
        "preds=Dense(69,activation='softmax')(x) #final layer with softmax activation\n",
        "\n",
        "model=Model(inputs=base_model.input,outputs=preds)\n",
        "\n",
        "for layer in model.layers[:87]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[87:]:\n",
        "    layer.trainable=True\n",
        "\n",
        "for i,layer in enumerate(model.layers):\n",
        "  print(i,layer.name, layer.trainable)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_10 False\n",
            "1 conv1_pad False\n",
            "2 conv1 False\n",
            "3 conv1_bn False\n",
            "4 conv1_relu False\n",
            "5 conv_dw_1 False\n",
            "6 conv_dw_1_bn False\n",
            "7 conv_dw_1_relu False\n",
            "8 conv_pw_1 False\n",
            "9 conv_pw_1_bn False\n",
            "10 conv_pw_1_relu False\n",
            "11 conv_pad_2 False\n",
            "12 conv_dw_2 False\n",
            "13 conv_dw_2_bn False\n",
            "14 conv_dw_2_relu False\n",
            "15 conv_pw_2 False\n",
            "16 conv_pw_2_bn False\n",
            "17 conv_pw_2_relu False\n",
            "18 conv_dw_3 False\n",
            "19 conv_dw_3_bn False\n",
            "20 conv_dw_3_relu False\n",
            "21 conv_pw_3 False\n",
            "22 conv_pw_3_bn False\n",
            "23 conv_pw_3_relu False\n",
            "24 conv_pad_4 False\n",
            "25 conv_dw_4 False\n",
            "26 conv_dw_4_bn False\n",
            "27 conv_dw_4_relu False\n",
            "28 conv_pw_4 False\n",
            "29 conv_pw_4_bn False\n",
            "30 conv_pw_4_relu False\n",
            "31 conv_dw_5 False\n",
            "32 conv_dw_5_bn False\n",
            "33 conv_dw_5_relu False\n",
            "34 conv_pw_5 False\n",
            "35 conv_pw_5_bn False\n",
            "36 conv_pw_5_relu False\n",
            "37 conv_pad_6 False\n",
            "38 conv_dw_6 False\n",
            "39 conv_dw_6_bn False\n",
            "40 conv_dw_6_relu False\n",
            "41 conv_pw_6 False\n",
            "42 conv_pw_6_bn False\n",
            "43 conv_pw_6_relu False\n",
            "44 conv_dw_7 False\n",
            "45 conv_dw_7_bn False\n",
            "46 conv_dw_7_relu False\n",
            "47 conv_pw_7 False\n",
            "48 conv_pw_7_bn False\n",
            "49 conv_pw_7_relu False\n",
            "50 conv_dw_8 False\n",
            "51 conv_dw_8_bn False\n",
            "52 conv_dw_8_relu False\n",
            "53 conv_pw_8 False\n",
            "54 conv_pw_8_bn False\n",
            "55 conv_pw_8_relu False\n",
            "56 conv_dw_9 False\n",
            "57 conv_dw_9_bn False\n",
            "58 conv_dw_9_relu False\n",
            "59 conv_pw_9 False\n",
            "60 conv_pw_9_bn False\n",
            "61 conv_pw_9_relu False\n",
            "62 conv_dw_10 False\n",
            "63 conv_dw_10_bn False\n",
            "64 conv_dw_10_relu False\n",
            "65 conv_pw_10 False\n",
            "66 conv_pw_10_bn False\n",
            "67 conv_pw_10_relu False\n",
            "68 conv_dw_11 False\n",
            "69 conv_dw_11_bn False\n",
            "70 conv_dw_11_relu False\n",
            "71 conv_pw_11 False\n",
            "72 conv_pw_11_bn False\n",
            "73 conv_pw_11_relu False\n",
            "74 conv_pad_12 False\n",
            "75 conv_dw_12 False\n",
            "76 conv_dw_12_bn False\n",
            "77 conv_dw_12_relu False\n",
            "78 conv_pw_12 False\n",
            "79 conv_pw_12_bn False\n",
            "80 conv_pw_12_relu False\n",
            "81 conv_dw_13 False\n",
            "82 conv_dw_13_bn False\n",
            "83 conv_dw_13_relu False\n",
            "84 conv_pw_13 False\n",
            "85 conv_pw_13_bn False\n",
            "86 conv_pw_13_relu False\n",
            "87 flatten_5 True\n",
            "88 dense_22 True\n",
            "89 dropout_6 True\n",
            "90 dense_23 True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jN7L4L-6m-H",
        "colab_type": "code",
        "outputId": "9af7792f-60fa-444d-9e68-b8ecf787cfe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1305
        }
      },
      "source": [
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "# Adam optimizer\n",
        "# loss function will be categorical cross entropy\n",
        "# evaluation metric will be accuracy\n",
        "\n",
        "\n",
        "early_stop = EarlyStopping(patience=3)\n",
        "\n",
        "step_size_train=train_generator.n//train_generator.batch_size\n",
        "step_size_valid=valid_generator.n//valid_generator.batch_size\n",
        "\n",
        "\n",
        "history = model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=step_size_train,\n",
        "                    epochs=14,\n",
        "                    validation_data=valid_generator,\n",
        "\t                  validation_steps=step_size_valid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-104-e7e19af401a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \t                  validation_steps=step_size_valid)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2669\u001b[0m                                 \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2671\u001b[0;31m                                 session)\n\u001b[0m\u001b[1;32m   2672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   2621\u001b[0m             \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2622\u001b[0m         \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2623\u001b[0;31m         \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2624\u001b[0m         \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2625\u001b[0m         \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     \"\"\"\n\u001b[1;32m   1470\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, callable_options)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m           self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[0;32m-> 1425\u001b[0;31m               session._session, options_ptr, status)\n\u001b[0m\u001b[1;32m   1426\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqHy45qG-Xou",
        "colab_type": "code",
        "outputId": "64b94793-b673-4d29-d349-39b78542bce4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(history.epoch,history.history['loss'])\n",
        "plt.title('loss')\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(history.epoch,history.history['acc'])\n",
        "plt.title('accuracy');"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "66/66 [==============================] - 23s 350ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.9895266522487645, 0.2349311819023355]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVExTueVPP3F",
        "colab_type": "text"
      },
      "source": [
        "# ResNet (doesn't work)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gEGhayEk05G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJCzW3k5C_vi",
        "colab_type": "code",
        "outputId": "840d3603-1598-468b-e067-6885b6e6cc4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1577
        }
      },
      "source": [
        "\n",
        "# create the base pre-trained model\n",
        "base_model = ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224, 224, 3), pooling='max', classes=69)\n",
        "\n",
        "\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(69, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "\n",
        "# train the model on the new data for a few epochs\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "\n",
        "model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=50\n",
        ")\n",
        "\n",
        "# at this point, the top layers are well trained and we can start fine-tuning\n",
        "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
        "# and train the remaining top layers.\n",
        "\n",
        "# let's visualize layer names and layer indices to see how many layers\n",
        "# we should freeze:\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "   print(i, layer.name)\n",
        "\n",
        "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
        "# the first 249 layers and unfreeze the rest:\n",
        "for layer in model.layers[:249]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[249:]:\n",
        "   layer.trainable = True\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "154/155 [============================>.] - ETA: 0s - loss: 15.8663"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-9ab8f24ac04b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEP_SIZE_VALID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    232\u001b[0m                             \u001b[0mval_enqueuer_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             workers=0)\n\u001b[0m\u001b[1;32m    235\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                         \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1470\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 raise ValueError('Output of generator should be a tuple '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OwLQ7QdEFLJ",
        "colab_type": "code",
        "outputId": "0a8efb94-6135-4a91-f436-cdcdceb4918d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "model = createModel()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmp2AmTyF4DI",
        "colab_type": "code",
        "outputId": "929f9900-5134-4ba6-b43f-3cff50f6f64b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "print(STEP_SIZE_TRAIN)\n",
        "print(STEP_SIZE_VALID)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "155\n",
            "66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvHg--83Ds2W",
        "colab_type": "code",
        "outputId": "572f4a01-4126-4c32-a200-497f0f4e0d08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "\n",
        "model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=100\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/10\n",
            "155/155 [==============================] - 86s 552ms/step - loss: 4.2369 - acc: 0.0103 - val_loss: 4.2341 - val_acc: 0.0147\n",
            "Epoch 2/10\n",
            "155/155 [==============================] - 79s 511ms/step - loss: 4.2351 - acc: 0.0119 - val_loss: 4.2341 - val_acc: 0.0147\n",
            "Epoch 3/10\n",
            "155/155 [==============================] - 77s 498ms/step - loss: 4.2351 - acc: 0.0115 - val_loss: 4.2339 - val_acc: 0.0157\n",
            "Epoch 4/10\n",
            "155/155 [==============================] - 78s 500ms/step - loss: 4.2394 - acc: 0.0141 - val_loss: 4.2341 - val_acc: 0.0152\n",
            "Epoch 5/10\n",
            "155/155 [==============================] - 77s 498ms/step - loss: 4.2351 - acc: 0.0115 - val_loss: 4.2341 - val_acc: 0.0142\n",
            "Epoch 6/10\n",
            "155/155 [==============================] - 78s 502ms/step - loss: 4.2348 - acc: 0.0145 - val_loss: 4.2341 - val_acc: 0.0142\n",
            "Epoch 7/10\n",
            "155/155 [==============================] - 78s 502ms/step - loss: 4.2349 - acc: 0.0105 - val_loss: 4.2340 - val_acc: 0.0157\n",
            "Epoch 8/10\n",
            "155/155 [==============================] - 78s 506ms/step - loss: 4.2350 - acc: 0.0125 - val_loss: 4.2342 - val_acc: 0.0128\n",
            "Epoch 9/10\n",
            "155/155 [==============================] - 78s 502ms/step - loss: 4.2349 - acc: 0.0137 - val_loss: 4.2341 - val_acc: 0.0133\n",
            "Epoch 10/10\n",
            "155/155 [==============================] - 79s 513ms/step - loss: 4.2348 - acc: 0.0111 - val_loss: 4.2341 - val_acc: 0.0161\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe0873c3908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b2Pe275DwRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate_generator(generator=valid_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6ATDEv_DzU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_generator.reset()\n",
        "pred=model.predict_generator(test_generator,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADA-qa5BD3uF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_generator.reset()\n",
        "pred=model.predict_generator(test_generator,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Xrk-93m_i_Z",
        "colab_type": "text"
      },
      "source": [
        "Sources Consulted\n",
        "\n",
        "https://medium.com/@vijayabhaskar96/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720"
      ]
    }
  ]
}